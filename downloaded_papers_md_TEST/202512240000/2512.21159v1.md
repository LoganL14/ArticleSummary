## From multitype branching Brownian motions to branching Markov additive processes

Yutao Liang ∗ , Yan-Xia Ren † , Quan Shi ‡ , Fan Yang §

December 25, 2025

## Abstract

We study a class of multitype branching L´ evy processes, where particles move according to type-dependent L´ evy processes, switch types via an irreducible Markov chain, and branch according to type-dependent laws. This framework generalizes multitype branching Brownian motions.

Using techniques of Markov additive processes, we develop a spine decomposition. This approach further enables us to prove convergence results for the additive martingales and derivative martingales, and establish the existence and uniqueness of travelling wave solutions to the corresponding multitype FKPP equations. In particular, applying our results to the on-off branching Brownian motion model resolves several open problems posed by Blath et al. (2025).

## 2020 Mathematics Subject Classification: 60J80, 60G51, 35K57.

Keywords: branching Brownian motion, Markov additive process, spine decomposition, FKPP equation, travelling wave.

## 1 Introduction

## 1.1 A motivating model: on-off branching Brownian motions

The starting point of this work is a model introduced by Blath et al. in [10]. Motivated by the biological concepts of dormancy and seed banks the authors proposed a branching particle system with two types: active and dormant. The two types are distinguished by different branching rates, reproduction laws, and motion dynamics. Furthermore, particles switch between the active and dormant states at certain rates. This system can be viewed as an extension of the well-known (single-type) branching Brownian motion (BBM) and is called on-off BBMs . Similar to the classical BBM, the on-off BBMs are connected to travelling wave solutions of twotype Fisher-Kolmogorov-Petrovskii-Piskounov (FKPP) equations, featured with dormancy mechanisms. While [10] establishes the convergence of additive martingales and the existence of travelling waves in the supercritical regime, several problems remain open, including the following ones posed by these authors [10, Section 4]:

- The uniqueness of the travelling waves.
- A probabilistic representation of the travelling waves akin to the Lalley-Sellke [38] construction.

∗ University of Chinese Academy of Sciences &amp; State Key Laboratory of Mathematical Sciences, Academy of Mathematics and Systems Science, Chinese Academy of Sciences; liangyutao@amss.ac.cn

† LMAM School of Mathematical Sciences &amp; Center for Statistical Science, Peking University; yxren@math.pku.edu.cn

‡ State Key Laboratory of Mathematical Sciences, Academy of Mathematics and Systems Science, Chinese Academy of Sciences; quan.shi@amss.ac.cn

§ School of Mathematical Sciences, Beijing University of Posts and Telecommunications; fan-yang@bupt.edu.cn

- Convergence of martingales and the existence of travelling waves in the critical regime.

A classical technique for addressing such questions is the spine decomposition, which is a seminal method in branching process theory (see e.g. [53]). However, its application to the on-off BBMs is non-trivial. Although the literature on single-type and multitype BBMs is vast, it usually assumes the underlying particle motion is identical for all types; this is crucially different from the on/off BBMs, where the motions of particles are typedependent. This seemingly minor extension introduces non-trivial technical difficulties. As Blath et al. note [10], 'the quadratic variation is truly probabilistic, making an application of the Girsanov Theorem difficult.' This inherent difficulty has thus posed a major obstacle to adapting the powerful spine decomposition technique.

One initial motivation for this work is to overcome this obstacle. We find that the essence of the problem is easier captured when we shift to a more general framework: branching particle systems with type-dependent L´ evy processes. This perspective is naturally related to Markov additive processes (MAPs), which provide a clearer view of the underlying structure and the necessary mathematical tools to handle the heterogeneity. In this framework, we introduce a new spine decomposition. This allows us to provide a systematic approach to studying such branching systems and, in particular, resolve several open problems identified by Blath et al. [10] mentioned above.

## 1.2 Multitype branching L´ evy processes viewed as branching MAPs

Our models are multitype branching L´ evy processes with a finite type space I = { 1 , . . . , d } , for some d ∈ N . Each particle is assigned a type i ∈ I and moves in R according to a type-dependent L´ evy process. They further randomly either branches, generating offspring that all inherit its current type, or switches to a new type. All particles evolve independently of one another. Specifically, the model is described as follows.

- (Movement) For each particle of type i ∈ I , its movement is governed by a R -valued L´ evy process ( χ i ( t ) , t ≥ 0). For θ ≥ 0, when the exponential moment E [ e -θχ i (1) ] is finite, we define the Laplace exponent ϕ i such that

<!-- formula-not-decoded -->

The Laplace exponent ϕ i is given by

<!-- formula-not-decoded -->

with σ 2 i ≥ 0, a i ∈ R and Λ i is a sigma-finite measure on R \ { 0 } . The generator A i f ( x ) is given by

<!-- formula-not-decoded -->

We assume at least one of χ i is non-trivial (non-constant).

- (Branching) At rate β i ≥ 0, a particle of type i gives birth to a number of offspring according to µ i := ( µ i ( k ) , k ≥ 0), and the children are all of type i and located at the same place as the death point of the parent. We suppose that each offspring has finite expectation

<!-- formula-not-decoded -->

- (Switching types) Each particle changes its type according to a continuous-time Markov chain Θ on I , with intensity matrix Q = ( q ij ) 1 ≤ i,j ≤ N , and possibly makes a jump at the time when it changes type. More precisely, at rate q ij ≥ 0, a particle of type i switches to the type j ∈ I , and at the same time makes

We always suppose that

̸

a jump in space according to the law of a real-valued random variable U ij , with convention that U ij = 0 if q ij = 0, and that U ii = 0. For i ∈ I , let q i = -q ii = ∑ j = i q ij . When E [ e -θU ij ] is finite, we define

<!-- formula-not-decoded -->

Q is irreducible .

As the state space is finite, we deduce that Θ is positively recurrent and admits a unique invariant distribution denoted by π = ( π i , i ∈ I ).

This model naturally includes the multitype BBMs as prototypes. Processes combining L´ evy behaviour with Markovian type-switching are known as the Markov additive processes (MAPs), which provides a suitable framework for our analysis. Specifically, consider a c` adl` ag process ( χ ( t )) t ≥ 0 on R , and a right-continuous jump process (Θ( t )) t ≥ 0 on I . Assume that the joint process ( χ, Θ) is adapted to a filtration ( H t ) t ≥ 0 satisfying the usual conditions.

Definition 1.1 (Markov additive process (MAP)). We say that ( χ ( t ) , Θ( t )) t ≥ 0 is a Markov additive process (MAP) if for all s, t ≥ 0 and i ∈ I , given { Θ( t ) = i } , the pair ( χ ( t + s ) -χ ( t ) , Θ( t + s )) is independent of H t and has the same law as ( χ ( s ) -χ (0) , Θ( s )) given { Θ(0) = i } .

The theory of MAPs is well-established and has prominent applications in e.g. classical applied probabilistic models for queues. We refer to [4, Chapter XI], [29, Chapter 2] and [18, Appendix] for detailed discussions. The following proposition is well-known, giving a standard representation for MAPs.

Proposition 1.2. Let ( χ ( t ) , Θ( t )) t ≥ 0 be a MAP. Let 0 = T 0 &lt; T 1 &lt; . . . be successive jump times of Θ . For each i, j ∈ I , there exist an i.i.d. sequence of random variables ( U n ij , n ≥ 1) , and an i.i.d. sequence of L´ evy processes ( χ n i , n ≥ 1) , such that these Θ , χ n i , U n ij are independent, and that for n ≥ 0 , t ∈ [ T n , T n +1 ) , where i = Θ( T n -) and j = Θ( T n ) .

<!-- formula-not-decoded -->

This representation has an intuitive interpretation: the process Θ governs a time-dependent random environment. When Θ is at state i ∈ I , the position χ evolves according to a copy of the L´ evy process χ i . Once Θ changes from i to j , χ has an additional transitional jump U ij . Then χ evolves according to a copy of χ j until the next jump of Θ. In this context, we say that ( χ, Θ) is a MAP associated with (( χ i ) i ∈I , Θ , ( U ij ) i,j ∈I ), or equivalently, with characteristic triplet (( ϕ i ) i ∈I , Q, G ). For α ≥ 0, suppose that ϕ i ( α ) &lt; ∞ , G ij ( α ) &lt; ∞ , i, j ∈ I . Then it is well-known that, for i, j ∈ I , where the matrix exponent F ( α ) is given by

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

where Q ◦ G ( α ) denotes the entrywise matrix multiplication of Q and G ( α ).

Therefore, we can define our multitype branching L´ evy process model, equivalently as a branching Markov additive process on the space R ×I as follows.

- The spatial motion and type-switching are governed by a MAP ( χ, Θ) associated with (( χ i ) i ∈I , Θ , ( U ij ) i,j ∈I );

- When a particle is located at ( x, i ) ∈ R × I , it splits at rate β i , giving birth to a random number of offsprings distributed according to µ i := ( µ i ( k ) , k ≥ 0), and the children are all initially located at the parent's position ( x, i ). Each offspring particle evolves independently of the others.

The construction of such a particle system may be carried out recursively in a genealogical manner, with the set of individuals indexed by the Ulam-Harris notation, thereby encoding the genealogy of the particles. More details are given in Section 2.3. Each particle indexed by u is assigned with birth time b u (the global time) and lifetime η u . For t ≥ 0, let N t be the collection of particles alive at time t , with u ∈ N t if and only if t ∈ [ b u , b u + η u )), and ( X u ( t ) , J u ( t )) be the position and state of the particle u ∈ N t . Denote by P x,i the probability law of the particle systems with one initial particle of type i ∈ I and position x ∈ R , and by E x,i the expectation under P x,i .

## 1.3 Main results

We can now state our main results. We define

<!-- formula-not-decoded -->

Note that 0 ∈ dom . Let ¯ θ := sup dom ∈ [0 , + ∞ ]. Then for each θ ∈ [0 , θ ), we have ϕ i ( θ ) &lt; ∞ and G ij ( θ ) &lt; ∞ for every i, j ∈ I . The subsequent results primarily assume ¯ θ &gt; 0 and utilize positive values of θ . If the domain of finiteness were confined to negative θ , one could apply a sign change by considering -X u ( t ), thereby shifting the analysis back to the positive regime.

Theorem 1.3 (Matrix exponent). For θ ∈ [0 , ¯ θ ) and i, j ∈ I , define

<!-- formula-not-decoded -->

Then for the matrix M ( θ ) ( t ) := ( M ( θ ) i,j ( t )) i,j ∈I , we have

<!-- formula-not-decoded -->

where the matrix exponent M ( θ ) is given by

<!-- formula-not-decoded -->

where Q ◦ G ( θ ) denotes the entry-wise multiplication of Q and G ( θ ) .

Let θ ∈ [0 , ¯ θ ). By the Perron-Frobenius (PF) theorem (see [52, Theorem 1.1] or [25, Theorem 8.3.4]), since M ( θ ) ( t ) is a matrix with positive entries, the matrix M ( θ ) has a PF eigenvalue λ ( θ ). This eigenvalue λ ( θ ) is real and larger than the real part of any other eigenvalues of M ( θ ), and its associated right eigenvector ⃗ V ( θ ) = ( V i ( θ ) , i ∈ I ) has strictly positive entries. Furthermore, because the entries of M ( θ ) are infinitely differentiable on (0 , ¯ θ ), the PF eigenvalue λ ( θ ) and the corresponding eigenvector ⃗ V ( θ ) are also infinitely differentiable on this interval. The properties above of the PF eigenvalue are introduced in Lemma 2.3 and Lemma 2.4.

̸

We observe that the number of particles (∑ u ∈N t ✶ { J u ( t )=1 } , . . . ∑ u ∈N t ✶ { J u ( t )= d } ) t ≥ 0 , forms a continuoustime multitype branching process (see e.g. [5]): for each particle of type i ∈ I , it is replaced by k particles of type i at rate β i µ i ( k ) for k ≥ 0; whereas it is replaced by one type j particle at rate q ij for j = i . When θ = 0, M (0) = Q + diag( β 1 m 1 -β 1 , . . . , β d m d -β d ) serves as the generator of the first moment semigroup of (∑ u ∈N t ✶ { J u ( t )=1 } , . . . ∑ u ∈N t ✶ { J u ( t )= d } ) t ≥ 0 and the PF eigenvalue λ (0) determines the extinction behaviour

with a phase transition. Denote the survival event by

<!-- formula-not-decoded -->

When λ (0) &gt; 0, the multitype branching process is called supercritical, and the survival probabilities P x,i ( S ) &gt; 0 for all i ∈ I . More precisely, define the extinction probabilities

<!-- formula-not-decoded -->

By [5, Theorem 2], the vector ⃗ q := ( q 1 , . . . , q d ) is the unique solution in [0 , 1] d \ { (1 , . . . , 1) } to the equation:

<!-- formula-not-decoded -->

The process also satisfies the 'positive regularity' and 'non-singularity' in [24, Theorem 2.7.1] and [24, Corollary 1 of Theorem 2.7.2]. Therefore the unique solution ⃗ q also lies in [0 , 1) d . Whereas when λ (0) ≤ 0, the extinction happens P x,i -a.s. ∀ x ∈ R , i ∈ I , i.e. P x,i ( S ) = 0.

In what follows, we will always work in the supercritical regime λ (0) &gt; 0. Summarizing, we assume that

<!-- formula-not-decoded -->

For each θ ∈ [0 , ¯ θ ), define

<!-- formula-not-decoded -->

By Theorem 1.3, ( W θ ( t )) t ≥ 0 is a P x,i -martingale. We call it the additive martingale. Since ( W θ ( t )) t ≥ 0 is a non-negative martingale, it converges a.s. to non-negative limit, denoted by W θ ( ∞ ). The following theorem gives the L 1 -convergence result for ( W θ ( t )) t ≥ 0 .

Theorem 1.4 ( L 1 -convergence). Let θ ∈ [0 , ¯ θ ) . On the event S , the additive martingale W θ ( t ) converges to W θ ( ∞ ) in L 1 ( P x,i ) for all x ∈ R , i ∈ I if and only if θλ ′ ( θ ) &lt; λ ( θ ) and ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; ∞ for all j ∈ I .

Moreover, when W θ converges in L 1 ( P x,i ) , we have P x,i ( { W θ ( ∞ ) &gt; 0 } ∆ S ) = 0 , where ∆ represents the symmetric difference between two sets.

By the main Theorem of [32], the function q ↦→ λ ( q ) is strictly convex on (0 , ¯ θ ). It follows that q ↦→ λ ( q ) q either attains its unique minimum in the interval (0 , ¯ θ ) or approaches the infimum at the boundaries 0 or ¯ θ (note that ¯ θ could be + ∞ ). The next assumption specifies that the minimum is attained in the interior.

- (A2) The function q ↦→ λ ( q ) q attains its unique minimum at some θ ∗ ∈ (0 , ¯ θ ); or equivalently, there exists θ ∗ ∈ (0 , ¯ θ ) such that λ ( θ ∗ ) = θ ∗ λ ′ ( θ ∗ ).

We refer to θ = θ ∗ as the critical regime; λ ( θ ) θ &lt; λ ′ ( θ ), corresponding to θ ∈ ( θ ∗ , ¯ θ ), as the subcritical regime; and λ ( θ ) θ &gt; λ ′ ( θ ), corresponding to θ ∈ (0 , θ ∗ ), as the supercritical regime. Under the assumption (A2), the L 1 -convergence in Theorem 1.4 only happens in the supercritical regime θ ∈ (0 , θ ∗ ).

As an application of Theorem 1.4, we obtain the velocity of the leftmost particle.

Corollary 1.5 (Velocity of the leftmost particle). Assume (A1), (A2), and ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; + ∞ , for all j ∈ I . Then, for any x ∈ R and i ∈ I , P x,i -a.s. on the non-extinction event S ,

<!-- formula-not-decoded -->

The main tool we use in the proof of Theorem 1.4 is the spine decomposition. The spine decomposition is a powerful technique in the study of branching processes. Typically, it contains two steps. The first step is a change of measure, and the second step is a deconstruction of the process in the new probability measure. For the details of the spine decomposition on classic branching systems, one can refer to [40, 53] for applications on branching random walks (BRWs), [34] for applications on branching Brownian motions (BBMs), and [48] for applications on branching Markov processes (BMPs). In our model, we established a spine decomposition, which is introduced formally in Section 2.3, and proved in Section 5. This framework provides a powerful tool for deeper analysis of the model, which we employ here to study the derivative martingale and the travelling waves.

For θ ∈ (0 , ¯ θ ), define the derivative martingale

<!-- formula-not-decoded -->

Note that we intuitively have Z θ ( t ) := -∂ θ W θ ( t ). At criticality θ = θ ∗ , the derivative martingale is a crucial object for understanding the fine structure of the frontier in branching systems; see, for example, [1, 53] for applications on branching random walks, [34, 38] for applications on BBMs and [50] for applications on multitype BBMs.

Using the spine decomposition, we prove the convergence of the critical derivative martingale.

Theorem 1.6 (Critical derivative martingale). Assume (A1) and (A2). Then Z θ ∗ ( t ) converges P x,i -a.s. to a non-negative limit Z θ ∗ ( ∞ ) , as t →∞ . If furthermore

<!-- formula-not-decoded -->

holds, then we have P x,i ( { Z θ ∗ ( ∞ ) &gt; 0 } ∆ S ) = 0 .

The FKPP equation is a well-known reaction-diffusion equation that appears in population genetics and ecology. Its connection to branching processes was first studied via probabilistic tools in [44]. Since then, it has been widely studied in probability, particularly in branching systems, see, for example, [12], [36], [34], [38] and [50]. In the study of FKPP equation, the existence, uniqueness and the asymptotic of the travelling wave solutions are particularly interested. One can find a 'common pattern' in these works of FKPP equations. In the supercritical regime, the travelling wave solutions are often strongly connected to the limit of the additive martingale; while in the critical regime, it is related to the limit of the derivative martingale; while in the subcritical regime, there is no travelling wave solution.

For i ∈ I , let g i ( s ) := ∑ k ≥ 0 µ i ( k ) s k , s ∈ [0 , 1], be the generating function of µ i , and A i be the generator given in (1.1). Our model is associated with the following FKPP type equation on R + × R ×I :

̸

<!-- formula-not-decoded -->

Indeed, we prove in Proposition 4.1 that u ( t, x, i ) := E x,i [∏ u ∈N t u (0 , X u ( t ) , J u ( t )) ] gives a mild solution of (1.6), in the sense that it satisfies the following integral equation:

̸

<!-- formula-not-decoded -->

If we look for constant solutions of the FKPP equation (1.6) of the form u ( t, x, i ) ≡ s i ∈ [0 , 1] for i ∈ I , then the problem reduces to solving the equation (1.4). As we have seen, it admits only two constant solutions in [0 , 1] d : ⃗ q = ( q 1 , . . . q d ) and (1 , . . . , 1). We are interested in studying non-constant, travelling wave solutions that connect these two equilibria. To this end, let us introduce the following class of functions R ×I → [0 , 1]:

<!-- formula-not-decoded -->

A travelling wave solution is then defined as follows.

Definition 1.7 (Travelling waves). Let ρ ∈ R and Φ ∈ T 1 . If u ( t, x, i ) := Φ( x -ρt, i ) is a solution of the FKPP equation (1.7) , then we say that Φ is a travelling wave solution with speed ρ .

Theorem 1.8 (Existence and uniqueness of travelling waves). Assume (A1), (A2), and θ ∈ (0 , ¯ θ ) .

- (i) (Supercritical regime) If θλ ′ ( θ ) &lt; λ ( θ ) and ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; ∞ for all j ∈ I , then the function Φ θ ( x, i ) = E x,i [ e -W θ ( ∞ ) ] = E 0 ,i [ e -e -θx W θ ( ∞ ) ] is a travelling wave solution with speed ρ θ = λ ( θ ) θ &gt; λ ( θ ∗ ) θ ∗ .
- (ii) (Critical regime) If θ ∗ λ ′ ( θ ∗ ) = λ ( θ ∗ ) and ∑ k ≥ 1 k (log k ) 2 µ j ( k ) &lt; ∞ for all j ∈ I , then Φ θ ∗ ( x, i ) = E x,i [ e -Z θ ∗ ( ∞ ) ] = E 0 ,i [ e -e -θx Z θ ∗ ( ∞ ) ] is a travelling wave solution with speed ρ θ ∗ = λ ( θ ∗ ) θ ∗ .
- (iii) (Subcritical regime) If ρ &lt; λ ( θ ∗ ) θ ∗ , there are no travelling wave solutions with speed ρ .

Suppose furthermore that the branching MAP is spectrally negative (that is the MAP ( χ, Θ) associated with (( χ i ) i ∈I , Θ , ( U ij ) i,j ∈I ) has no positive jumps), then the travelling wave solutions given in the supercritical and critical regimes are unique in T 1 .

## 1.4 Related works

Branching Brownian motion (BBM) and branching random walks (BRW) are canonical probabilistic models, with significant applications in statistical physics and population biology. These processes provide insights for understanding phenomena ranging from the extremes of log-correlated random fields and the structure of mean-field spin glasses to the dynamics described by diffusion-reaction equations. The classical case of a single particle type has been extensively studied. For a comprehensive treatment, we refer the reader to [53] and [11].

For branching L´ evy process, there have been a recent increasing interests; see [47, 26, 28, 49], to list just a few. An extended model with infinite branching rate has been introduced by [9] and the martingale convergence results have been studied in [8, 43].

The theory of branching processes has been generalized to the multitype case. Kesten and Stigum [31] established a key limit theorem for the discrete-time multitype branching processes, using the famous L log L moment condition for the reproduction law. Athreya [5] proved this result for continuous-time settings. In the context of branching Brownian motion, Ren and Yang [50] studied irreducible multitype cases, offering a probabilistic proof for the existence, uniqueness and asymptotic behaviours of the corresponding travelling wave solutions. More recently, Hou et al. [27] proved that the extremal process of an irreducible multitype branching Brownian motion converges weakly to a cluster point process. For reducible cases, two-type branching Brownian motions have been investigated in [7] and [41]. Note that, a common assumption in these works on multitype BBM has been that all particle types share the same underlying motion process. This is distinct from our setting, where the underlying processes differ among types.

A further generalization considers types in a general measurable space, which introduces significant new challenges, even without the presence of the spatial motion. There are significant new challenges. For the analysis of survival properties, we refer to [3] for an L log L condition in the model with countably many types, and to [42] for a comprehensive treatment of the case with uncountably many types.

## 1.5 Examples: two-type BBMs

To make connections with results in [10, 12], let us exam in detail a specific case of our model: a two-type branching Brownian motion. Particles have two types { 1 , 2 } . For i = 1 , 2, a type i particle undergoes a Brownian motion with drift a i ∈ R and variance σ 2 i &gt; 0; it branches at rate β i ≥ 0 into offspring of the same type at its current location, with offspring numbers distributed according to µ i . Furthermore, at rate q 1 &gt; 0 (for type 1) or q 2 &gt; 0 (for type 2), the particle switches to the other type without displacement. All particles evolve independently. Let m i = ∑ k ≥ 1 µ i ( k ) k , i = 1 , 2. Assume β 1 ( m 1 -1) + β 2 ( m 2 -1) &gt; 0 and σ 2 1 + σ 2 2 &gt; 0 to avoid degenerate cases.

The matrix exponent in Theorem 1.3 is given by

<!-- formula-not-decoded -->

where f i ( θ ) := 1 2 σ 2 i θ 2 -a i θ -q i + β i ( m i -1), i = 1 , 2. Then explicit calculation shows that the PF eigenvalue is

<!-- formula-not-decoded -->

with its corresponding PF eigenvector

<!-- formula-not-decoded -->

Then M ( θ ) and λ ( θ ) are finite for every θ ∈ (0 , + ∞ ). We check by the explicit formula of λ ( θ ) that λ (0+) &gt; 0, and when θ → + ∞ , λ ( θ ) θ → + ∞ . There is a unique minimum in (0 , + ∞ ) of the function q ↦→ λ ( q ) q , achieved at the solution θ ∗ of λ ′ ( θ ∗ ) θ ∗ = λ ( θ ∗ ). Therefore assumptions (A1) and (A2) are satisfied.

For i ∈ { 1 , 2 } , recall in (1.6), g i ( s ) = ∑ ∞ k =0 µ i ( k ) s k . The corresponding FKPP equation is given by

<!-- formula-not-decoded -->

Having checked all the assumptions, we conclude that the statements in Theorem 1.4, Corollary 1.5, Theorem 1.6 and Theorem 1.8 (including the uniqueness part) all hold for the two-type branching Brownian motion.

A connection with in [10] This formulation of two-type branching Brownian motions encompasses the on-off branching Brownian motion models proposed by [10], where the two types are referred to as 'active' and 'dormant'. When β 2 = σ 2 = 0, we obtain the Variant I model defined by [10, (1.16)]; when β 2 = σ 1 = 0, we obtain the variant II model in [10, (1.19)].

In [10], although not explicitly stated, the last formula on page 10 has assumed ∑ k 2 µ 1 ( k ) &lt; ∞ . This already implies ∑ k ( k log 2 k ) µ i ( k ) &lt; ∞ . Compared to [10], our work provides several extensions:

- For the linear speed of the leftmost particle, the result matches [10, Theorem 1.9].
- When θ &gt; θ ∗ , we deduce the same results on the additive martingale [10, Proposition 2.7] and travelling waves [10, Theorem 1.13].
- When 0 &lt; θ &lt; θ ∗ , we have the same results on the additive martingale [10, Theorem 2.3 and Proposition 2.4] and travelling waves [10, Theorem 1.10].
- When θ = θ ∗ , we include new results on martingale convergence, and also the existence and uniqueness

of the travelling wave solutions, answering the open questions in [10].

A connection with [12] The model in [12] is recovered by setting the drifts to zero ( a i = 0) and requiring strictly positive branching rates ( β i &gt; 0 for i = 1 , 2). In [12], Since the production law is given by µ 1 (2) = µ 2 (2) = 1, it also satisfies ∑ k ( k log 2 k ) µ i ( k ) &lt; ∞ . Our results are consistent with [12]:

- For the linear speed of the leftmost particle, the result matches the speed in [12, Theorem 1.41].
- When θ &gt; θ ∗ , we include the non-existence of the travelling wave solutions.
- When 0 &lt; θ &lt; θ ∗ , the L 1 -convergence is consistent with [12, Theorem 1.39]. We also deduce the same existence and uniqueness results in [12, Theorem 1.41].
- When θ = θ ∗ , we include new results on martingale convergence, and also the existence and uniqueness of the travelling wave solutions.

## 1.6 Perspectives and further questions

1. Generalization to non-local branching with infinite branching rate It is straightforward to extend our models to include non-local branching governed by a point process. We can further accommodate infinite branching rates as in [9], using similar approximation methods given there. This generalization would establish a connection with multitype growth-fragmentations [16, 17].

2. Necessary conditions for the non-triviality of the derivative martingale limit For the singletype BBM case, (1.5) has been proven to be necessary and sufficient for the critical derivative martingale to converge to a non-trivial limit in [55]; similar results are also known as the A¨ ıd´ ekon-Chen condition for single-type BRWs [1, 15], and for branching L´ evy processes with infinite branching rates [43]. We conjecture that an analogous statement still holds for our multitype model, namely the condition (1.5) is both necessary and sufficient. Indeed, we believe that the methods from [43] should be applicable to our model; however, a full proof would require a further study of the perpetual integral of a conditioned MAP.

3. Uniqueness of travelling waves In Theorem 1.8, the assumption of spectrally negative jumps is used to establish uniqueness. We believe this assumption is redundant. Extending the result to processes with twosided jumps requires a more refined analysis. We expect that the techniques from [2], which first establishes asymptotics of the travelling waves and then use these to prove uniqueness, are applicable.

4. Finer study of the leftmost position and extremal process It would be interesting to develop a refined analysis of the leftmost position, e.g. by studying the convergence of min u ∈N t X u ( t ) + λ ( θ ∗ ) θ ∗ t as well as the extremal process. This is closely related to the convergence of FKPP solutions to travelling waves and the precise information on the front propagation. The spine decomposition in the current work allows the methods in [53] to be adapted to the multitype setting.

5. Infinitely many types Anatural generalization is to consider more general type spaces, with countable or uncountable infinitely many types. Comparing with finitely many types, this can lead to significantly different behaviours; for example, local extinction of each type would no longer be equivalent to global extinction of the entire population [3]. This framework naturally connects to heterogeneous models of spatially dependent branching and movement. Developing such an extension would require studies on general Markov additive processes, where the underlying modulating processes are general Markov processes, as opposed to Markov chains on a finite space; see [42] for recent development.

## 1.7 Organization of the paper

The remaining of this work is organized as follows. In Section 2, we first introduce preliminary tools for MAPs and establish the spine decomposition theorem. Then we apply the spine decomposition to deduce the L 1 -convergence of the additive martingales (Theorem 1.4) and determine the velocity of the leftmost particle (Corollary 1.5). In Section 3, we prove Theorem 1.6 the convergence of the critical derivative martingale and give a sufficient condition for the limit to be non-trivial. In Section 4, we use the martingale limits to give a probabilistic representation of the travelling wave solutions, and therefore prove the existence and uniqueness (Theorem 1.8). The proofs treat the supercritical and the critical regimes separately. In Section 5, we give detailed proofs of the spine decomposition theorem, including a 'Girsanov transformation' of MAPs.

## 2 The Spine decomposition

## 2.1 Preliminaries on MAPs

This section provides the necessary preliminaries on Markov additive processes (MAPs) defined as in Definition 1.1. We refer to [29, Chapter 2] and [18, Appendix] for detailed discussions on this topic.

Recall from Proposition 1.2 that a MAP ( χ, Θ) is associated with a family of L´ evy processes ( χ i ) i ∈I with respective Laplace exponents ( ϕ i ) i ∈I , a Markov chain with intensity matrix Θ and a family of random variables ( U ij ) i,j ∈I with Laplace transform G = ( G ij ) i,j ∈I . The matrix exponent of the MAP F ( α ) is given by (1.2). Since Θ is irreducible, the entries of the matrix e F ( α ) t are all strictly positive. From the Perron-Frobenius (PF) theory, F ( α ) admits a PF eigenvalue which is real and larger than the real part of any other eigenvalues; see for example [52, Theorem 1.1]. Based on the PF eigenvalue, we have the following law of large numbers.

Proposition 2.1 ( [29, Propositions 2.13, 2.15 and Lemma 2.14]). Suppose ( χ ( t ) , Θ( t )) t ≥ 0 is a MAP with matrix exponent F ( α ) = diag( ϕ i ( α )) i ∈I + Q ◦ G ( α ) . Let γ ( α ) be the Perron-Frobenius eigenvalue of F ( α ) . Then γ ( α ) is infinitely differentiable for α &gt; 0 , and one can define γ ′ (0) as the right derivative. Moreover, it holds that P x,i -a.s.

<!-- formula-not-decoded -->

for all i ∈ I and x ∈ R , where π = ( π i ) i ∈I is the stationary distribution of Markov chain Θ . Moreover, when the MAP is not degenerate (not constant) and E π [ χ (1)] = 0 , it holds that P x,i -a.s.

<!-- formula-not-decoded -->

The following lemma for the perpetual integral of a MAP will be used to prove Theorem 3.2. For more studies on the perpetual integrals of L´ evy processes we refer to [6, 33].

Lemma 2.2. Let ( χ ( t ) , Θ( t )) t ≥ 0 be a MAP. Suppose Θ is irreducible. Let f : R + × I → R + be a bounded non-negative measurable function. Suppose that f is eventually non-increasing and that

<!-- formula-not-decoded -->

Denote τ 0 := inf { t ≥ 0 : χ ( t ) &lt; 0 } . Then we have, for any x &gt; 0 and i ∈ I ,

<!-- formula-not-decoded -->

Proof. In this proof we denote by C n &gt; 0 suitable constants for n ≥ 1. We first treat the case when χ is

non-lattice. Using [18, Theorem 27], we have

<!-- formula-not-decoded -->

Here ( R + i,j ) i,j ∈I are the potential measures for the ascending ladder height process associated with ( χ, Θ), and ( R -i,j ) i,j ∈I are those for the descending ladder height process; see [18, Equation (27)] for more details. When χ is lattice, then each L´ evy process χ i is a compound Poisson process on the same lattice { r Z } for some r &gt; 0, and the analysis is similar to discrete random walks. In this case, the renewal measures can be expressed via the (strong or weak) ascending ladders, analogous to the renewal measure for discrete random walks. Let ( R &gt; i,j ) i,j ∈I denote the renewal measures for the strongly ascending ladder height process of χ , and let ( R ≤ i,j ) i,j ∈I denote the renewal measures for the weakly descending ladder height process. Specifically, we define the renewal measures as follows. Let T &gt; 0 := 0 (resp. T ≤ 0 := 0) and define recursively for n ≥ 0 that T &gt; n +1 := inf { t &gt; T &gt; n : χ ( t ) &gt; χ ( T &gt; n ) } (resp. T ≤ n +1 := inf { t &gt; T ≤ n : χ ( t ) ≤ χ ( T &gt; n ) } ). Let H &gt; n := χ ( T &gt; n ) (resp. H ≤ n := χ ( T ≤ n )) be the strongly ascending (resp. weakly descending) ladder heights. Then we define, for integer m ≥ 0 and k ≤ 0,

<!-- formula-not-decoded -->

Then by similar arguments as in the proof of [18, Theorem 27], we deduce a lattice analogue (c.f. [54, Page 209 P3] for the random walk case) of (2.2):

<!-- formula-not-decoded -->

It follows from the Markov renewal theorem (see e.g. [37] or [4, Section VII.4]) that they are non-negative and there exists A &gt; 0 1 such that

<!-- formula-not-decoded -->

For simplicity, we only consider non-lattice case in the rest of the proof. The proof also works for lattice case if we replace R + i,j and R -i,j with R &gt; i,j and R ≤ i,j .

Recall that f is bounded and eventually non-increasing; replacing the value of f on a compact set by a constant, we can find a function ̂ f ≥ f , which is bounded and non-increasing such that

<!-- formula-not-decoded -->

1 Note that it holds in fact for any A &gt; 0 for the non-lattice case; for the lattice case, take A larger than the span.

As (2.1) holds, we also have ∫ R + ̂ f ( x, k )d x &lt; ∞ . Since ̂ f is bounded and non-increasing, we deduce that

<!-- formula-not-decoded -->

It follows that

<!-- formula-not-decoded -->

Plugging this inequality to (2.2), we have

<!-- formula-not-decoded -->

which is finite under the assumption (2.1).

## 2.2 The Matrix exponent and Perron-Frobenius eigenvalue

In this section, we prove Theorem 1.3 and then introduce some properties of the Perron-Frobenius eigenvalue (PF eigenvalue).

̸

Proof of Theorem 1.3. We decompose the process at the first time when the initial particle branches or changes its type; when the initial particle starts at type i , it has exponential distribution with parameter β i + q i , where q i := ∑ l = i q il = -q ii . By the branching property, we have, for every t ≥ 0

̸

<!-- formula-not-decoded -->

Let D ( θ ) ( t ) := diag ( e t ( ϕ i ( θ ) -β i -q i ) ) 1 ≤ i ≤ d , C := diag( β i m i ) 1 ≤ i ≤ d , and E := diag ( q i ) 1 ≤ i ≤ d . Then by the previous equation we have

<!-- formula-not-decoded -->

Let B ( θ ) := diag (( ϕ i ( θ ) -β i -q i )) 1 ≤ i ≤ d . Then

<!-- formula-not-decoded -->

Therefore,

<!-- formula-not-decoded -->

where we used the definition of M ( θ ) given by (1.3). We deduce from this integral equation that M ( θ ) ( t ) = e t M ( θ ) , ∀ t ≥ 0.

As mentioned in Section 1, we introduce some preliminary results on the Perron-Frobenius (PF) theory in the following Lemmas; see for example [52, Theorem 1.1] or [25, Theorem 8.3.4] for proofs.

Lemma 2.3. Let M ( θ ) be defined by (1.3) and let λ ( θ ) denote the PF eigenvalue. Then we have:

1. λ ( θ ) is real and larger than the real part of any other eigenvalues of M ( θ ) .
2. The eigenvector w.r.t. λ ( θ ) is unique up to constant multiplication. Let ⃗ Y ( θ ) = ( Y 1 ( θ ) , . . . Y d ( θ )) ⊤ and ⃗ V ( θ ) = ( V 1 ( θ ) , . . . V d ( θ )) ⊤ denote the corresponding left and right eigenvectors respectively. Without loss of generality, we normalize the two eigenvectors with π ⊤ ⃗ V ( θ ) = 1 and ⃗ Y ⊤ ( θ ) ⃗ V ( θ ) = 1 , where π = ( π 1 , . . . , π d ) ⊤ is the stationary distribution of Markov chain J . The entries of ⃗ Y ( θ ) and ⃗ V ( θ ) are all strictly positive.
3. If ⃗ U ( θ ) is a right eigenvector of M ( θ ) with positive entries, then we have ⃗ U ( θ ) = c ⃗ V ( θ ) for some c &gt; 0 .

With the same method as in the proof of Proposition 2.13 of [29], we have the following lemma on differentiability of λ ( θ ) and V ( θ ).

Lemma 2.4. With the notation of Lemma 2.3, each of the functions θ ↦→ λ ( θ ) , ⃗ Y ( θ ) and ⃗ V ( θ ) is infinitely differentiable on (0 , ¯ θ ) . Moreover, we have

<!-- formula-not-decoded -->

where M ′ ( θ ) is the entry-wise derivative of M ( θ ) .

In the rest of the paper, we refer to λ ( θ ) as the PF eigenvalue of M ( θ ) and V ( θ ) as the PF eigenvector, with the same normalization in Lemma 2.3.

## 2.3 Measure change by the additive martingale

Let us first give a formal construction of our branching MAP model as a marked Galton-Watson tree. Let N = { 1 , 2 , 3 , . . . } . Denote the Ulam-Harris labels by

<!-- formula-not-decoded -->

A planar tree τ is a subset of U such that

- ∅ ∈ τ (the ancestor);
- for u, v ∈ U , uv ∈ τ implies u ∈ τ ;
- for all u ∈ τ, there exists A u ∈ { 1 , 2 , . . . } such that for j ∈ N , uj ∈ τ if and only if 1 ≤ j ≤ A u .

Let T be the space of planar trees. We use the notation v ≺ u to denote that v is an ancestor of u .

For a branching MAP, we denote the initial particle by ∅ ∈ U and its birth time by b ∅ = 0. Say it is initially located at x ∈ R with type i ∈ I . Then we define ( X ∅ , J ∅ ) to be a MAP with triplet (( ϕ i ) i ∈I , Q, G ) starting from ( x, i ). Let us recursively construct a tree τ ∈ T and assigned each particle u ∈ τ with a mark ( X u , J u , η u , A u ) in the following way.

- For each particle u ∈ τ , given the birth time b u and ( X u ( t ) , J u ( t )) t ≥ b u , its lifetime η u is specified by the first jump time of a non-homogeneous Poisson process with rate β J u ( s -b u ) , s ≥ 0. At the death time d u := b u + η u , the particle u gives birth to an offspring, with the number of children A u distributed according to the offspring law µ J u ( d u ) , all located at X u ( d u ) with type J u ( d u ).
- For each child particle v = uj with j = 1 , . . . A u , its birth time is b v := d u . We construct a process ( X v ( t ) , J v ( t )) t ≥ b v such that ( X v ( s + b v ) , J v ( s + b v )) s ≥ 0 is a MAP with triplet (( ϕ i ) i ∈I , Q, G ) starting from ( X v ( b v ) , J v ( b v )) = ( X u ( d u ) , J u ( d u )), independent of the others.

We write ( τ, M ) as a shorthand for the marked Galton-Watson tree { ( u, X u , J u , η u , A u ) : u ∈ τ } . The statespace is T = { ( τ, M ) : τ ∈ T } and we denote its law by P x,i . For s ≤ t and u ∈ N t , we still use ( X u ( s ) , J u ( s )) to denote the position and type of particle u or its ancestor at time s . For t ≥ 0, define F t to be the σ -algebra generated by

<!-- formula-not-decoded -->

Set F = ∪ t ≥ 0 F t .

Assume (A1) holds and let θ ∈ (0 , ¯ θ ). For t ≥ 0, recall that N t denote the particles alive at time t . Then u ∈ N t if b u ≤ t &lt; d u and ( X u ( t ) , J u ( t )) gives its position and type at time t . Recall that the additive martingale is

<!-- formula-not-decoded -->

It follows from Theorem 1.3 that W θ ( t ) has constant expectation. The Markov property then implies that it is a non-negative martingale under P x,i for all x ∈ R and i ∈ I .

For any x ∈ R , i ∈ I , define a new probability measure P θ x,i by

<!-- formula-not-decoded -->

We next study the process under the new measure P θ x,i by the spine approach. For simplicity, we first introduce the definition of the spine under the assumption that each particle has at least one child. However, all the results in this subsection also hold for the case allowing the possibility of no offspring when a particle dies. For this general case, we give the details at the end of Section 5.1. Specifically, a spine is a distinguished genealogical line of descendants from the ancestor. We write the spine as ξ = { ξ t : t ≥ 0 } , where ξ t ∈ τ is the

label of the distinguished particle at time t . We write u ∈ ξ if u = ξ t for some t ≥ 0. Let O u be the set of u 's children except the one in the spine. Now let

<!-- formula-not-decoded -->

be the space of marked trees in T with a distinguished spine ξ . Recall that the filtration ( F t ) t ≥ 0 contains all the information about the marked tree. Then we define for every t ≥ 0 a new sigma-algebra by adding the information of the spine:

<!-- formula-not-decoded -->

Let ˜ F := ∪ t ≥ 0 ˜ F t .

Let J ξ := ( J ξ t ( t ) , t ≥ 0) denote the type process of the spine and X ξ := ( X ξ t ( t ) , t ≥ 0) its spatial movement. We also use X ξ ( t ) and J ξ ( t ) as shorthand for X ξ t ( t ) and J ξ t ( t ), respectively. For u ∈ τ , we use | u | to denote the generation of u . Define n t := | ξ t | , which tells us which generation the spine node is in, then n := ( n t , t ≥ 0) is the counting process of fission times along the spine. Define

<!-- formula-not-decoded -->

We extend P x,i on ( T , F ) to a probability measure ˜ P x,i on ( ˜ T , ˜ F ) so that the spine is a single genealogical line of descendants chosen from the underlying tree. Since the children of a particle with type j are all of type j , we assume that at each fission time along the spine we make a uniform choice among the offspring. Then for u ∈ τ , we have

Lemma 2.5. For t ≥ 0 , define

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

Then the process ( ζ t , t ≥ 0) is a ˜ P x,i -martingale with respect to { ˜ F t , t ≥ 0 } .

The proof of Lemma 2.5 is postponed to Section 5. Now define a probability measure ˜ P θ x,i on ( ˜ T , ˜ F ) by

<!-- formula-not-decoded -->

By (2.5), we deduce that

˜ E x,i [ ζ t ✶ { ξ t = u } | F t ] = e -θX u ( t ) -λ ( θ ) t V J u ( t ) ( θ ) ✶ { u ∈N t } . It follows that ˜ E x,i [ ζ t | F t ] = ∑ u ∈N t e -θX u ( t ) -λ ( θ ) t V J u ( t ) ( θ ) = W θ ( t ) and thus the projection of ˜ P θ x,i on F is P θ x,i . Consequently, we also deduce that

<!-- formula-not-decoded -->

Indeed, for any B ∈ F t , we have by (2.6) and (2.5) that

<!-- formula-not-decoded -->

Since the projection of ˜ P θ x,i on F t is P θ x,i , we also have by (2.3) that

<!-- formula-not-decoded -->

This completes the proof of (2.7).

To describe the particle system under the law ˜ P θ x,i , we introduce the following change of measure for MAPs, which is a variation of [46, Proposition 5.6]; its proof is postponed to Section 5.

Lemma 2.6. For any x ∈ R and i ∈ I , let ( χ, Θ) be a MAP with triplet (( ϕ i ) i ∈I , Q, G ) under law P x,i . For θ ∈ (0 , ¯ θ ) , define

<!-- formula-not-decoded -->

It is a P x,i -martingale. Define a new probability measure P θ x,i by

<!-- formula-not-decoded -->

where ( F ( χ, Θ) t , t ≥ 0) is the natural filtration of the MAP ( χ, Θ) . Then under P θ x,i , (( χ, Θ) t ≥ 0 ) is a MAP with the following characteristics: for k, j ∈ I ,

̸

<!-- formula-not-decoded -->

̸

Therefore the corresponding MAP triplet is given by ( ( ˜ ϕ i ) i ∈I , ˜ Q := ( ˜ q kj ) k,j ∈I , ˜ G := ( ˜ G kj ) k,j ∈I ) , where ˜ ϕ k ( α ) = ϕ k ( α + θ ) -ϕ k ( θ ) for k ∈ I , and ˜ G kj ( α ) = G kj ( α + θ ) G kj ( θ ) for k, j ∈ I .

We now give the spine decomposition for ˜ P θ x,i and the proof is also postponed in Section 5. Since the projection of ˜ P θ x,i on F is P θ x,i , the latter is also described by this spine decomposition.

Theorem 2.7 (Spine decomposition). Let x ∈ R and i ∈ I . Under ˜ P θ x,i , the branching MAP is described as follows.

- The spine ξ evolves according to a MAP ( χ, Θ) of law P θ x,i with characteristics given by (2.9) .
- Given the type process J ξ ( t ) of the spine, the branching rate of the spine at time t ≥ 0 is given by β J ξ ( t ) m J ξ ( t ) ; when it splits, it gives birth to an offspring of the same type at the same position. The number of children is given by the size-biased law ( ˜ µ j ( k ) := kµ j ( k ) m j , k ≥ 1) , for j ∈ I .
- Choose one child uniformly at random, which continues as the spine; for the other children, each of them

leads a subpopulation of the original law P shifted to their point and time of creation. The spine continues in a similar way.

A direct consequence is the following many-to-one formula, which is well-known in context of branching particle systems: for every non-negative measurable function g and any ( x, i ),

<!-- formula-not-decoded -->

## 2.4 Proof of Theorem 1.4

Before proving Theorem 1.4, we first give some lemmas.

Lemma 2.8. For any x ∈ R , i ∈ I , the linear speed of the spine under ˜ P θ x,i is

<!-- formula-not-decoded -->

Proof. According to Lemma 2.6, under ˜ P θ x,i , the spine behaves as a MAP with matrix exponent

<!-- formula-not-decoded -->

For each i ∈ I , set ˜ V i ( α ) := V i ( θ + α ) V i ( θ ) and note that G ii ( θ ) = G ii ( θ + α ) = 1, we have

̸

<!-- formula-not-decoded -->

̸

̸

Therefore, ( ˜ V 1 ( α ) , . . . , ˜ V d ( α ) ) is an eigenvector of F ( α ) with all entries positive. Then it is a PF eigenvector of ˜ F ( α ), with the PF eigenvalue ˜ λ ( α ) = λ ( α + θ ) -λ ( θ ). Then, according to Lemma 2.1, the MAP has a linear speed of -( ˜ λ ) ′ (0) = -λ ′ ( θ ).

We are now ready to prove Theorem 1.4.

Proof of Theorem 1.4.

The degenerate phase Suppose that at least one of the following two conditions hold: (i) θλ ′ ( θ ) ≥ λ ( θ ); (ii) there exists some j ∈ I such that ∑ k ≥ 1 ( k log k ) µ j ( k ) = + ∞ . We next show that lim sup t →∞ W θ ( t ) = + ∞ ˜ P θ x,i -a.s. and then by [19, Theorem 4.3.5] we conclude that W θ ( t ) converges to 0, P x,i -a.s.

(i) We first assume that θλ ′ ( θ ) ≥ λ ( θ ). Under ˜ P θ x,i , the branching system does not extinct. For t ≥ 0,

<!-- formula-not-decoded -->

By Lemma 2.8, we have lim t →∞ X ξ ( t ) /t = -λ ′ ( θ ), ˜ P θ x,i -a.s. Thus, when θλ ′ ( θ ) &gt; λ ( θ ), we have

<!-- formula-not-decoded -->

When θλ ′ ( θ ) = λ ( θ ), by Proposition 2.1, we also have (2.11). Therefore lim sup t →∞ W θ ( t ) = + ∞ , ˜ P θ x,i -a.s.

(ii) We next assume that there exists some j ∈ I such that ∑ k ≥ 1 ( k log k ) µ j ( k ) = + ∞ . We also assume that θλ ′ ( θ ) &lt; λ ( θ ); otherwise it falls into the first case.

Let N j ( n ) denote the total number of fissions (branchings) in the spine ξ (across all types) by the time state j undergoes its n -th fission. Furthermore, let T n be the n -th fission time of the spine. Under this definition, at time T N j ( n ) , the spine ξ undergoes its n -th fission on state j for all n ≥ 1. Therefore { A ξ ( T N j ( n ) ) := A ξ T N j ( n ) } n ≥ 1 is an i.i.d. sequence with law ( ˜ µ j ( k )) k ≥ 1 . Since ˜ E θ x,i [ log A ξ ( T N j ( n ) ) ] = 1 m j ∑ k ≥ 1 ( k log k ) µ j ( k ) = + ∞ , by BorelCantelli's lemma,

<!-- formula-not-decoded -->

For t ≥ 0, j ∈ I , define D j ( t ) := ∫ t 0 ✶ { J ξ ( s )= j } d s as the cumulative time the spine spends in state j by time t . For n ≥ 1, D j ( T N j ( n ) ) denotes the cumulative time spent in state j up to the occurrence of the n -th fission event on state j . Since the spine undergoes fissions at rate ˜ β j := β j m j when in state j , the strong law of large numbers implies

<!-- formula-not-decoded -->

Since ( J ξ ( t ) , t ≥ 0) is an irreducible Markov chain under ˜ P θ x,i , we have lim t →∞ D j ( t ) t = ˜ π j a.s., where ( ˜ π j ) j ∈I is the invariant distribution of ( J ξ ( t ) , t ≥ 0). Notice that T N j ( n ) →∞ as n →∞ , then we have

<!-- formula-not-decoded -->

According to Theorem 2.7, the process ( T n ) n ≥ 1 is a Cox process on R + directed by ( J ξ ( t )) t ≥ 0 with rate ˜ β J ξ ( t ) d t . Since min l ∈I ˜ β l ≤ ˜ β J ξ ( t ) ≤ max l ∈I ˜ β l for all t ≥ 0, the n -th arrival time T n is stochastically bounded by the n -th arrival time of two Poisson point processes with intensity max l ∈I ˜ β l d t and min l ∈I ˜ β l d t . Then we have

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

Combining (2.13), (2.14), and (2.15) we have

<!-- formula-not-decoded -->

By (2.17) and (2.12), we have

<!-- formula-not-decoded -->

which implies

At time T n , we have a lower bound

<!-- formula-not-decoded -->

In the case of θλ ′ ( θ ) &lt; λ ( θ ) and ∑ k ≥ 1 ( k log k ) µ j ( k ) = + ∞ for some j ∈ I , by (2.16), (2.18) and (2.19), we again have lim sup t →∞ W θ ( t ) = + ∞ , ˜ P θ x,i -a.s.

The L 1 -convergence phase On the other hand, assume that θλ ′ ( θ ) &lt; λ ( θ ) and ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; ∞ for all j ∈ I . We prove that the additive martingale converges in L 1 ( P x,i ). Recall that G is defined by (2.4), being the σ -field generated by the motion and type of the spine, its fission time and its children. By [53, Lemma 4.2], it suffices to show:

<!-- formula-not-decoded -->

With notation in section 2.3, we have the following decomposition:

<!-- formula-not-decoded -->

By (2.21), we have

<!-- formula-not-decoded -->

When θλ ′ ( θ ) &lt; λ ( θ ), the first term above converges to 0, ˜ P θ x,i -a.s. Since ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; + ∞ for ∀ j ∈ I , by the Borel-Cantelli lemma, we have

<!-- formula-not-decoded -->

Therefore, for any j ∈ I , by (2.15), there exists c j &gt; 0 such that

<!-- formula-not-decoded -->

Then we have (2.20).

We now show that, when W θ converges in L 1 ( P x,i ), we have W θ ( ∞ ) &gt; 0 on the non-extinction event S . Define w ( i ) := P x,i ( W θ ( ∞ ) = 0), for i ∈ I , and ⃗ w := ( w (1) , . . . , w ( d )). Note that w ( i ) does not depend on x .

<!-- formula-not-decoded -->

This implies (2.22).

We then show that, P x,i -a.s. on S , we have

<!-- formula-not-decoded -->

Using Proposition 2.1 to the spine under ˜ P θ x,i yields that

<!-- formula-not-decoded -->

Therefore, lim sup t → + ∞ L t t ≤ -λ ′ ( θ ) , P θ x,i -a.s. Since Theorem 1.4 yields that P θ x,i and P x,i are equivalent on the non-extinction event S , we have lim sup t → + ∞ L t t ≤ -λ ′ ( θ ) almost surely under P x,i . Optimizing in θ ∈ (0 , θ ∗ ) yields (2.24).

Combining (2.22) and (2.24), and using the identity λ ′ ( θ ∗ ) = λ ( θ ∗ ) θ ∗ from (A2), we complete the proof.

̸

By [19, Theorem 4.3.5], when W θ converges in L 1 ( P x,i ), we have E x,i [ W θ ( ∞ ) W θ (0) ] = 1. This implies ⃗ w = (1 , . . . , 1). By strong Markov property on the first branching/type-changing time, we have

̸

<!-- formula-not-decoded -->

for i ∈ I . This is equivalent to the equation:

<!-- formula-not-decoded -->

This is the same equation as (1.4). Then ⃗ w is the unique solution on [0 , 1] d \ { (1 , . . . , 1) } of the equation, and therefore ⃗ w = ⃗ q , i.e. P x,i ( W θ ( ∞ ) = 0) = P x,i ( S c ). Note that S c ⊆ { W θ ( ∞ ) = 0 } . This implies P x,i ( { W θ ( ∞ ) &gt; 0 } ∆ S ) = 0.

## 2.5 Velocity of the leftmost particle

Proof of Corollary 1.5. For simplicity, we write L t := min u ∈N t X u ( t ).

We first show that, P x,i -a.s. on S , we have

<!-- formula-not-decoded -->

We start by deriving a simple lower bound for W θ ( t ) on S .

<!-- formula-not-decoded -->

By Theorem 1.4 , when θ ∈ [ θ ∗ , ¯ θ ), the additive martingale W θ ( t ) converges to 0, P x,i -a.s. Therefore by the above inequality, P x,i -a.s. on S

<!-- formula-not-decoded -->

## 3 Convergence of the derivative martingales

In this section, we assume (A1) (A2) and prove Theorem 1.6 for the derivative martingale at criticality θ = θ ∗ . The proof relies on a study of the truncated derivative martingales that we introduce in section 3.1.

## 3.1 Truncated derivative martingales

Recall the spine decomposition in Section 2.3. Under assumption (A2), we perform the change of measure with the critical value θ = θ ∗ . Then the spine ( X ξ ( t ) , J ξ ( t )) t ≥ 0 under ˜ P θ ∗ x,i is a MAP with matrix exponent given by Lemma 2.6. Define

<!-- formula-not-decoded -->

In particular, we have ˜ E θ ∗ x,i [ ̂ X ξ ( t )] = 0 and ˜ E θ ∗ x,i [ ̂ X 2 ξ ( t )] &lt; ∞ .

For x ∈ R , let τ x := inf { t ≥ 0: ̂ X ξ ( t ) &lt; x } . According to [18, Theorem 29], there exists finite and non-negative functions ( R i ) i ∈I , such that the process

<!-- formula-not-decoded -->

✶ The function ( R i ) i ∈I are continuous and non-decreasing, which are referred to as the renewal functions for the MAP ( ̂ X ξ ( t ) , J ξ ( t )) t ≥ 0 .

Lemma 3.1. There exists a constant c ren ∈ (0 , ∞ ) , such that for every i ∈ I ,

<!-- formula-not-decoded -->

Proof. Since ˜ E θ ∗ x,i [( -̂ X ξ ) 2 ( t )] &lt; ∞ , we know from [18, Theorem 35 and Lemma 38] that ( -̂ X ξ , J ξ ) has tight overshoot under ˜ P θ ∗ x,i , and equivalently, ∑ j ∈I ˜ π j ˜ E θ ∗ 0 ,i [ H -(1)] ∈ (0 , ∞ ), where H -is the so-called descending ladder height process of ( ̂ X ξ , J ξ ) under ˜ P θ ∗ 0 ,i and ˜ π is the stationary distribution of J ξ ( t ) under ˜ P θ ∗ 0 ,i . 2 Then it follows from the Markov renewal theory (see e.g. [37] or [18, Theorem 28 (i)]; note that the version we use here holds for the lattice case as well) that

<!-- formula-not-decoded -->

For b &gt; max( -θ ∗ x, 0), we define the truncated derivative martingale under P x,i :

<!-- formula-not-decoded -->

where ̂ X u ( t ) := θ ∗ X u ( t ) + λ ( θ ∗ ) t . Indeed, applying the many-to-one formula (2.10) and then (3.1), we have

<!-- formula-not-decoded -->

Then it follows from the branching property that Z ( b ) θ ∗ ( t ) is a non-negative martingale under P x,i , and therefore converges a.s. to a limit Z ( b ) θ ∗ ( ∞ ) ≥ 0 as t →∞ .

The convergence of the derivative martingale, stated in Theorem 1.6, would rely on the L 1 convergence of the truncated derivative martingale Z ( b ) θ ∗ . We give the following theorem.

2 Note that, as remarked by [18, Page 1995], we do not require non-lattice assumption.

Theorem 3.2 (Uniform integrability). Let x ∈ R and b &gt; max( -θ ∗ x, 0) . Assume (A1), (A2), and (1.5) . Then Z ( b ) θ ∗ is a uniform integrable martingale under P x,i , and E x,i [ Z ( b ) θ ∗ ( ∞ ) Z ( b ) θ ∗ (0) ] = 1 .

## 3.2 Proof of Theorem 3.2

In this subsection we prove Theorem 3.2. To simplify the analysis, we perform the linear transformation ̂ X u ( t ) = θ ∗ X u ( t ) + λ ( θ ∗ ) t , t ≥ 0. This yields a new branching MAP ( ̂ X u ( t ) , J u ( t )) for which assumption (A2) becomes:

<!-- formula-not-decoded -->

Since the results are preserved under the linear transformation, it suffices to prove for the transformed branching MAP, and then the corresponding statements for the original branching MAP follow immediately.

Therefore, we assume that the assumptions (A1) and (A3) hold for the branching MAP ( X u ( t ) , J u ( t )) and prove Theorem 3.2. To study the L 1 convergence of the truncated derivative martingale Z ( b ) θ ∗ , let us introduce a further change of measure. For any x ≥ -b and i ∈ I , let ˜ P θ ∗ x,i be defined as in (2.6) with θ ∗ = 1. Recall by Lemma 2.6 that the spine ( X ξ ( t ) , J ξ ( t )) under ˜ P θ ∗ x,i is a MAP with characteristics given by (2.9). Then define a change of measure by the martingale (3.1) associated with the spine: for every t ≥ 0,

<!-- formula-not-decoded -->

To describe the law of the spine under ˜ P ↑ x,i , let us denote by P θ ∗ x,i the law of a MAP ( χ, Θ) with characteristics given by (2.9) and define a change of measure:

<!-- formula-not-decoded -->

Then P ↑ x,i is known as the law of a MAP conditioned to stay positive ; we refer to [18, Appendices A.7-A.8] for more details. L´ evy processes (with single type) conditioned to stay positive have been the subject of a large literature; we refer to [13] and reference therein. Define P ↑ x,i as the projection of ˜ P ↑ x,i on ( T , F ). By projection (2.7) and change of measure (2.3), we also deduce the connection with the original law P x,i : for t ≥ 0,

<!-- formula-not-decoded -->

Similar to Theorem 2.7 for ˜ P θ ∗ x,i , under ˜ P ↑ x,i , we also have a spinal description of the dynamics, specified in the following proposition. The only difference lies in the spine's movement. Specifically, the spine under ˜ P ↑ x,i is a MAP conditioned to stay positive, whereas under ˜ P θ ∗ x,i it is unconditioned. For completeness we give a proof of Proposition 3.3 in Section 5.3.

Proposition 3.3. Let x ∈ R and i ∈ I . Under ˜ P ↑ x,i , the branching MAP is described as follows.

- There is a spine starting from position x with type i and moves according to a MAP conditioned to stay positive defined by (3.4) .
- Given the type process Θ of the spine, the branching rate at time t ≥ 0 is given by β Θ t m Θ t ; when it splits,

it gives birth to an offspring of the same type at the same position. The number of children is given by the size-biased law ˜ µ j ( k ) := kµ j ( k ) m j , for k ≥ 1 and j ∈ I .

- Choose one child uniformly at random, which continues as the spine; each of the other children leads a subpopulation of the original law P , independent of each other. The spine continues in a similar way.

Proof of Theorem 3.2. Denote by M (d s, d k ) the counting measure (on R + × Z &gt; 0 ) of the spine's fission times and number of children. Let G be the σ -field generated by the spine ( X ξ , J ξ ) and M , as given in Lemma 2.21. By [53, Lemma 4.2], to show that ( Z ( b ) θ ∗ ( t ) , t ≥ 0) is uniformly integrable, and E x,i [ Z ( b ) θ ∗ ( ∞ ) Z ( b ) θ ∗ (0) ] = 1, it suffices to prove that

<!-- formula-not-decoded -->

By the spinal decomposition, we have

<!-- formula-not-decoded -->

As X ξ ( t ) under ˜ P ↑ x,i is a MAP conditioned to stay above -b , by [18, Proposition 33] we have lim t →∞ X ξ ( t ) = + ∞ ˜ P ↑ x,i -a.s. Therefore the first term above converges to 0, ˜ P ↑ x,i -a.s.

To deal with the second term, we divide the above integral into two parts

<!-- formula-not-decoded -->

We now prove that A 1 and A 2 are both ˜ P ↑ x,i -a.s. finite.

Recall that M is a Cox process, in the sense that given ( X ξ ( t ) , J ξ ( t )) t ≥ 0 , the conditional distribution of M is a Poisson point process with intensity ˜ β J ξ ( t ) d t ⊗ d ˜ µ J ξ ( t ) , with each ˜ µ i the size-biased offspring distribution. Let C I := max i ∈I ˜ β i &gt; 0. The compensation formula leads to

<!-- formula-not-decoded -->

Since ∫ R 2 j ( b + x ) V j ( θ ∗ ) e -x e x/ 3 d x ≤ C ∫ x 2 e -2 x/ 3 d x &lt; ∞ , by Lemma 2.2, ˜ E ↑ x,i [ A 1 ] &lt; ∞ , and therefore, A 1 &lt; ∞ , ˜ P ↑ x,i -a.s.

On the other hand, to prove A 2 is ˜ P ↑ x,i -a.s. finite, it suffices to prove that the following integral is finite:

<!-- formula-not-decoded -->

Again, by the compensation formula, we have

<!-- formula-not-decoded -->

Applying Lemma 2.2 with f ( r, j ) := ( b + r ) ∑ k ≥ 1 ˜ µ j ( k ) { 3 log k&gt;r } , we obtain

<!-- formula-not-decoded -->

This is finite under the assumption (1.5), as we have

<!-- formula-not-decoded -->

Applying Lemma 2.2 with f ( r, j ) leads to ˜ E ↑ x,i [ I ] &lt; ∞ . This completes the proof of (3.5), thereby establishing the desired result.

## 3.3 Proof of Theorem 1.6

Proof of Theorem 1.6. Applying (2.23) to the critical parameter θ ∗ = 1, we deduce that

<!-- formula-not-decoded -->

Fix ε &gt; 0. By (3.6), there exists b = b ( ε ) ≥ 0 such that P x,i (inf t ≥ 0 inf u ∈N t X u ( t ) ≥ -b | S ) ≥ 1 -ε .

We consider the truncated martingale Z ( b ) θ ∗ . Recall that, for any fixed δ &gt; 0, we have by Lemma 3.1 that, for all u sufficiently large, ( c ren -δ ) u ≤ R i ( u ) ≤ ( c ren + δ ) u , for all i ∈ I . We define

<!-- formula-not-decoded -->

Then on the event S ∩ { inf t ≥ 0 inf u ∈N t X u ( t ) ≥ -b } , when t is sufficiently large, we have

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

As t → ∞ , we have by Theorem 1.4 (the critical case) that W θ ∗ ( t ) converges to 0, P x,i -a.s. and that that or equivalently

Z ( b ) θ ∗ ( t ) converges to a nonnegative limit Z ( b ) θ ∗ ( ∞ ), P x,i -a.s. on S . Then letting δ → 0, we conclude that

<!-- formula-not-decoded -->

We claim that lim t →∞ ( Z θ ∗ ( t ) -Z ′ θ ∗ ( t )) = 0, on { inf t ≥ 0 inf u ∈N t X u ( t ) ≥ -b } ∩ S . By definition, we have

<!-- formula-not-decoded -->

Since I is a finite set, { V ′ i ( θ ∗ ) V i ( θ ∗ ) } i ∈I is a bounded set. Then (3.7) is dominated by the additive martingale W ( t ), thus converges to 0, P x,i -a.s.

Therefore we have already proved, on the event { inf t ≥ 0 inf u ∈N t X u ( t ) ≥ -b } ∩ S , c ren · lim t →∞ Z θ ∗ ( t ) = Z ( b ) θ ∗ ( ∞ ). Finally, letting b → + ∞ , as lim b →∞ P x,i (inf t ≥ 0 inf u ∈N t X u ( t ) ≥ -b ∣ ∣ S ) = 1, we deduce the P x,i -a.s. convergence on S of the derivative martingale Z and the identity

<!-- formula-not-decoded -->

Moreover, if (1.5) holds, then by Theorem 3.2, E x,i [ Z ( b ) θ ∗ ( ∞ ) Z ( b ) θ ∗ (0) ] = 1. The identity above implies that P x,i ( Z θ ∗ ( ∞ ) &gt; 0) &gt; 0. We claim that P x,i ( Z θ ∗ ( ∞ ) = 0) does not depend on x . In fact, ∀ x ∈ R , we have

<!-- formula-not-decoded -->

Therefore,

<!-- formula-not-decoded -->

Similar to the analysis in the proof of Theorem 1.4, denote ϖ ( i ) := P x,i ( Z θ ∗ ( ∞ ) = 0). Then ( ϖ ( i )) i ∈I will satisfy equation (1.4), which yields ⃗ ϖ = ⃗ q . On the other hand, S c ⊆ { Z θ ∗ ( ∞ ) = 0 } . Consequently, we have P x,i ( { Z θ ∗ ( ∞ ) &gt; 0 } ∆ S ) = 0.

## 4 FKPP equations and travelling waves

Recall that, for ρ ∈ R and a function Φ ∈ T 1 , with T 1 given by (1.8), Φ is called a travelling wave solution of the FKPP equation (1.7) with speed ρ , if u ( t, x, i ) := Φ( x -ρt, i ) is a solution of (1.7), i.e. Φ satisfies the equation

̸

<!-- formula-not-decoded -->

By setting ̂ χ i ( t ) := χ i ( t ) + ρt , we have equivalently

̸

<!-- formula-not-decoded -->

Note that the generator of ̂ χ i is A i + ρ ∂ ∂x , with A i given by (1.1). Then the travelling wave Φ is a mild solution of the following equations: for i ∈ I ,

̸

<!-- formula-not-decoded -->

In this section we prove Theorem 1.8. We first present in Section 4.1 the multiplicative martingale that is related to a travelling wave, and then prove the existence and uniqueness in Sections 4.2 and 4.3 respectively.

## 4.1 Martingale problem

Let us first build a connection between a branching MAP and a FKPP equation (1.7).

Proposition 4.1. Let u 0 : R ×I → [0 , 1] be a measurable function. For t ≥ 0 x ∈ R and i ∈ I , we define

<!-- formula-not-decoded -->

with the usual convention ∏ i ∈∅ c i = 1 . Then the function u is a solution of the FKPP equation (1.7) .

Proof. Recall that, the initial particle of type i ∈ I moves according to a L´ evy process χ i . By decomposition at the first time when it branches or switches to a different type, we have

̸

<!-- formula-not-decoded -->

Applying this expression to u ( t -s, χ i ( s ) , i ) leads to

<!-- formula-not-decoded -->

Note that, by the Markov property of a L´ evy process, we have

<!-- formula-not-decoded -->

Taking expectation to (4.2) and changing variables with w = s + r , with an application of the Markov property,

̸

we deduce that

<!-- formula-not-decoded -->

̸

Integrating (4.3) over s , then adding to u ( t, x, i ) and using Fubini's theorem, we conclude that

̸

<!-- formula-not-decoded -->

A change of variables yields the equation.

Proposition 4.2 (Martingale problem). For any θ ∈ (0 , ¯ θ ) , a function Φ θ ∈ T 1 is a travelling wave with speed ρ θ = λ ( θ ) θ , if and only if

<!-- formula-not-decoded -->

is a martingale under E x,i , for any i ∈ I .

Proof. Let Φ θ ∈ T 1 be a solution of the martingale problem with speed ρ θ . By the martingale property, for every x ∈ R and t ≥ 0 we have the identity

<!-- formula-not-decoded -->

It follows from Proposition 4.1 that u ( t, x, i ) := Φ θ ( x -ρ θ t, i ) is a solution of the FKPP with initial condition u (0 , x, i ) = Φ θ ( x, i ), so by definition Φ θ is a travelling wave.

Conversely, let Φ θ be a travelling wave with speed ρ θ . Our goal is to prove that ∏ u ∈N t Φ θ ( X u ( t )+ ρ θ t, J u ( t )) is a martingale. Applying Proposition 4.1 to the branching MAP ( ̂ X u ( t ) = X u ( t ) + ρ θ t, t ≥ 0), we have the identity

̸

<!-- formula-not-decoded -->

Due to (4.1), the latter is equal to Φ θ ( x, i ). Therefore, E x,i [ ∏ u ∈N t Φ θ ( x + ̂ X u ( t ) , J u ( t )) ] = Φ( x, i ) is a constant for every t . It follows from the Markov property that ∏ u ∈N t Φ θ ( ̂ X u ( t ) , J u ( t )) is a martingale under P x,i .

## 4.2 Proof of existence of travelling waves

We assume (A1) (A2) and show the existence of travelling wave solution with speed ρ &gt; λ ( θ ∗ ) θ ∗ . Recall that, by the convexity of λ , θ ↦→ λ ( θ ) θ strictly decreases from + ∞ to λ ( θ ∗ ) θ ∗ on (0 , θ ∗ ]. Therefore, for any ρ &gt; λ ( θ ∗ ) θ ∗ , there exists a unique θ ∈ (0 , θ ∗ ) such that ρ = λ ( θ ) θ . Recall that W θ ( t ) = e -λ ( θ ) t ∑ u ∈N t e -θX u ( t ) V J u ( t ) ( θ ) and W θ ( ∞ ) = lim t →∞ W θ ( t ) almost surely under P x,i .

Lemma 4.3. Suppose θ ∈ (0 , ¯ θ ) with θλ ′ ( θ ) &lt; λ ( θ ) and ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; ∞ for all j ∈ I . Define a function Φ θ : R ×I → [0 , 1] by ( x, i ) ↦→ Φ θ ( x, i ) = E x,i [ e -W θ ( ∞ ) ] = E 0 ,i [ e -e -θx W θ ( ∞ ) ] . Then Φ θ is a travelling wave solution with speed λ ( θ ) θ .

Proof. First, it follows from the spatial homogeneity of the branching MAP that

<!-- formula-not-decoded -->

This yields that E x,i [ e -W θ ( ∞ ) ] = E 0 ,i [ e -e -θx W θ ( ∞ ) ] and Φ θ ( x, i ) is well defined. Moreover, it follows from Theorem 1.4 that when θλ ′ ( θ ) &lt; λ ( θ ) and ∑ k ≥ 1 ( k log k ) µ j ( k ) &lt; ∞ for all j ∈ I , W θ ( ∞ ) is non-degenerate and P 0 ,i ( W θ ( ∞ ) = 0) = q i . Thus we have

<!-- formula-not-decoded -->

Since Φ θ ( x, i ) = E 0 ,i [ e -e -θx W θ ( ∞ ) ] and W θ ( ∞ ) is non-negative, we get that x ↦→ Φ θ ( x, i ) is non-decreasing in x . Thus, Φ θ ∈ T 1 .

By the decomposition at time s ≥ 0, we deduce that, P x,i -a.s.,

<!-- formula-not-decoded -->

where W ( u ) θ ( ∞ ) is the limit of the additive martingale for the branching Markov additive process starting from ( X u ( s ) , J u ( s )); given F s , { W ( u ) θ ( ∞ ) : u ∈ N s } are conditionally independent.

For t ≥ 0, x ∈ R and i ∈ I , with Φ θ in the statement, we define

<!-- formula-not-decoded -->

Let 0 ≤ s ≤ t , then by (4.4) and the branching property, we get that

<!-- formula-not-decoded -->

In particular, setting s = t , we have

<!-- formula-not-decoded -->

It follows from Proposition 4.1 that u ( t, x, i ) satisfies the FKPP equation. Recall that u ( t, x, i ) := Φ θ ( x -λ ( θ ) θ t, i ) , then Φ θ is a travelling wave with speed λ ( θ ) θ by definition.

Recall that Z θ ∗ ( ∞ ) is the limit of the derivative martingale with the critical parameter.

Lemma 4.4. Suppose ∑ k ≥ 1 k (log k ) 2 µ j ( k ) &lt; ∞ for all j ∈ I . Then the function Φ θ ∗ ( x, i ) = E x,i [ e -Z θ ∗ ( ∞ ) ] = E 0 ,i [ e -e -θx Z θ ∗ ( ∞ ) ] is a travelling wave solution with speed λ ′ ( θ ∗ ) = λ ( θ ∗ ) θ ∗ .

Proof. Using the argument similar to the proof of Lemma 4.3, we have that Φ θ ∗ is well defined and Φ θ ∗ ∈ T 1 . Recall that Z θ ∗ ( t ) = e -λ ( θ ∗ ) t ∑ u ∈N t e -θ ∗ X u ( t ) [ V J u ( t ) ( θ ∗ )( X u ( t ) + λ ′ ( θ ∗ ) t ) -V ′ J u ( t ) ( θ ∗ ) ] and Z θ ∗ ( ∞ ) = lim t →∞ Z θ ∗ ( t ) almost surely under P x,i . Therefore, we know that under P x,i ,

<!-- formula-not-decoded -->

where W ( u ) θ ∗ ( ∞ ) and Z ( u ) θ ∗ ( ∞ ) are the limits of the additive martingale and derivative martingale for the Markov branching additive process starting from ( X u ( s ) , J u ( s )), respectively, and given F s , { ( W ( u ) θ ∗ ( ∞ ) , Z ( u ) θ ∗ ( ∞ ) : u ∈ N s } are independent. Since lim t →∞ W θ ∗ ( t ) = 0 almost surely, we have

<!-- formula-not-decoded -->

The remaining arguments are very similar to the proof of Theorem 4.3 and we omit the details.

Proof Theorem 1.8: the existence part. By Lemmas 4.3 and 4.4, it remains to show the non-existence of travelling waves with speed ρ &lt; λ ( θ ∗ ) θ ∗ . The proof is an extension of classical arguments (see e.g. [22]). By Corollary 1.5 the velocity of the leftmost particle is -λ ′ ( θ ∗ ). As ρ &lt; λ ( θ ∗ ) θ ∗ = λ ′ ( θ ∗ ), we have P x,i -a.s.

<!-- formula-not-decoded -->

Let Φ be a solution of the martingale problem with parameter ρ , then for every t ≥ 0, it holds that

<!-- formula-not-decoded -->

Since Φ ∈ T 1 , we have P x,i -a.s. on S ,

<!-- formula-not-decoded -->

By Fatou's lemma, we deduce that Φ( x, i ) ≤ q i +(1 -q i ) max j ∈I q j for all x ∈ R and i ∈ I . Choose i 0 ∈ I such that q i 0 = max j ∈I q j . Thus, Φ( x, i 0 ) ≤ q i 0 +(1 -q i 0 ) q i 0 = 1 -(1 -q i 0 ) 2 &lt; 1 for all x ∈ R , which contradicts to the fact that Φ ∈ T 1 .

## 4.3 Proof of uniqueness of travelling waves

We now prove the uniqueness of travelling waves, for which we further assume that the branching MAP is spectrally negative; this assumption means that, for all i ∈ I , the L´ evy process χ i has no positive jumps (its L´ evy measure satisfies Λ i (0 , ∞ ) = 0) and P ( U ij ≤ 0) = 1 for all i, j ∈ I . In this proof, we follow the general ideas of [34, 55].

Proof Theorem 1.8: the uniqueness part. We treat the supercritical ( θ ∈ (0 , ¯ θ )) and critical ( θ = θ ∗ ) regimes separately.

Supercritical regime Let θ ∈ (0 , ¯ θ ) with ρ θ = λ ( θ ) θ &gt; λ ( θ ∗ ) θ ∗ . Consider a branching MAP under law P 0 ,i and define the space-time barrier

<!-- formula-not-decoded -->

When a particle crosses this barrier, it is stopped immediately. According to [51, Theorem 46.2], a L´ evy process without positive jumps that crosses an upper barrier from below must do so continuously. Consequently, a particle governed by such a process is stopped upon hitting the barrier. Let C ( x, ρ θ ) denotes the random collection of particles stopped at the barrier, then is a stopping line , as it satisfies the fundamental property that, if u ∈ C ( x, ρ θ ), then v / ∈ C ( x, ρ θ ) for all v ≺ u ; see [14, 30]. Then we have the following properties.

- For any u ∈ C ( x, ρ θ ) and v ≺ u , we have v / ∈ C ( x, ρ θ ). By (2.23), we have that lim t →∞ (min u ∈N t X u ( t ) + ρ θ t ) = ∞ P x 0 ,i -a.s. on S , then all lines of descendants from the ancestor hit Γ ( x,ρ θ ) for all x &gt; x 0 .
- lim x →∞ inf {| u | : u ∈ C ( x, ρ θ ) } = ∞ , where | u | is the generation of the particle u . This follows from the fact that the number of offspring in the n -th generation is finite almost surely, and their life lengths are finite almost surely. Therefore, max { X u ( s ) : | u | = n, s ≤ d u } must be finite almost surely. Then, we get that inf {| u | : u ∈ C ( x, ρ θ ) } tends to infinity as x →∞ .
- For x &lt; y and any u ∈ C ( y, ρ θ ), there exists a unique v ∈ C ( x, ρ θ ) such that v ≺ u . This follows from the first point and the fact that when the particles hit the barrier. Let F Γ ( x,ρ θ ) be the natural filtration generated by ancestral types and spatial paths receding from particles at the moment they hit Γ ( x,ρ θ ) (see [14, 30] for precise definition). Therefore, for x &lt; y , F Γ ( x,ρ θ ) ⊂ F Γ ( y,ρ θ ) .
- Let C j ( x, ρ θ ) denotes the random collection of type j particles stopped at the barrier Γ ( x,ρ θ ) . We claim that (# C j ( x, ρ θ ) : j ∈ I ) forms a supercritical continuous-time branching process where x ≥ 0 plays the role of time. First, we use P ( x,t ) ,i to denote the law of branching MAP with the initial particle starting from space-time position ( x, t ) of type i . Then it follows from the spatial homogeneity of MAP that for ( x 1 , t 1 ) , ( x 2 , t 2 ) ∈ Γ ( x,ρ θ ) , we have (# C j ( y, ρ θ ) : j ∈ I ; P ( x 1 ,t 1 ) ,i ) d. = (# C j ( y, ρ θ ) : j ∈ I ; P ( x 2 ,t 2 ) ,i ) with y &gt; x and any i ∈ I . Moreover, the law of (# C j ( y, ρ θ ) : j ∈ I ; P ( x 1 ,t 1 ) ,i ) only depends on the 'time' y -x between the stopping lines and the type i of the initial particle.

We use σ x u to denote the stopping time when the particle u hit the barrier Γ ( x,ρ θ ) . By the strong Markov branching property on stopping lines (see [14, 45] for branching Brownian motions and [35] for branching L´ evy processes), we know that given F Γ ( x,ρ θ ) , the processes (# C j ( y, ρ θ ) : j ∈ I , y &gt; x ; P ( X u ( σ x u ) ,σ x u ) ,J u ( σ x u ) ) for u ∈ N t are independent. Therefore, (# C j ( x, ρ θ ) : j ∈ I ; P 0 ,i ) satisfies the definition on [5, Page 200] and forms a continuous-time branching process indexed by x ≥ 0.

Moreover, since all lines of descendants from the ancestor will hit the barrier Γ ( x,ρ θ ) , we know that the process along the stopping line will survive on the event S . Thus, the continuous-time branching process (# C j ( x, ρ θ ) : j ∈ I , x ≥ 0) is supercritical.

Define m θ ij ( x ) := E 0 ,i [# C j ( x, ρ θ )], i, j ∈ I . Since the matrix Q of the branching MAP is irreducible, we have that the matrix M θ ( x ) := ( m θ ij ( x )) i,j ∈I is irreducible. By the property of a continuous-time branching process, there exists a positive matrix A θ such that M θ ( x ) = e xA θ . By the Perron-Frobenius theorem, A θ has a positive PF eigenvalue η θ with corresponding right and left eigenvectors ⃗ h θ := ( h θ i : i ∈ I ) and ⃗ π θ := ( π θ i : i ∈ I ) such that ⟨ ⃗ π θ , ⃗ h θ ⟩ = ⟨ ⃗ π θ , 1 ⟩ = 1. Therefore,

<!-- formula-not-decoded -->

Furthermore, by the Kesten-Stigum theorem (see, for example, [20, Theorem 2.1]), we know that

<!-- formula-not-decoded -->

for some non-negative random variable ˜ W θ .

We next define

<!-- formula-not-decoded -->

Recall by Theorem 1.4 that W θ ( ∞ ) = lim t →∞ W θ ( t ) holds P 0 ,i -a.s. and in L 1 ( P 0 ,i ). By the strong Markov property at the stopping line, we have that

<!-- formula-not-decoded -->

where we used the fact { u ∈ N t : σ x u &gt; t } → ∅ as t → ∞ . Then ( ˜ W x ( ρ θ ) , x ≥ 0) is a P 0 ,i -martingale with respect to {F Γ ( x,ρ θ ) : x ≥ 0 } and

<!-- formula-not-decoded -->

Note that m θ ij ( x ) = E 0 ,i [# C j ( x, ρ θ )]. Taking expectation on the both sides of (4.7) and then letting x → ∞ , we get that

<!-- formula-not-decoded -->

Therefore, combining (4.10) with (4.5), we have η θ = θ and h θ i = cV i ( θ ). Then, (4.6) will be

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

On the other hand, let Φ θ be a travelling wave with speed ρ θ . For z ∈ R , define

<!-- formula-not-decoded -->

Then, we claim that ( ˜ M x ( z, ρ θ ) , x ≥ 0) is a P 0 ,i -martingale with respect to {F Γ ( x,ρ θ ) : x ≥ 0 } . To see this, we define

<!-- formula-not-decoded -->

By Proposition 4.2, ( M t ( z, ρ θ ) , t ≥ 0) is a non-negative bounded martingale with respect to {F t : t ≥ 0 } .

By (4.9) again,

Therefore, P 0 ,i -a.s.

<!-- formula-not-decoded -->

exists and is non-degenerated. Similarly as (4.8), we deduce by the bounded convergence theorem and the strong Markov property that

<!-- formula-not-decoded -->

where we also used the fact that lim t →∞ (min u ∈N t X u ( t ) + ρ θ t ) = ∞ , P 0 ,i -a.s. on S (see (2.23)), and that lim t →∞ ∏ u ∈N t ,σ x u &gt;t Φ θ ( z + X u ( t ) + ρ θ t, J u ( t )) = 1 on S c . Thus, ( ˜ M x ( z, ρ θ ) , x ≥ 0) is a P 0 ,i -martingale and converges to M ∞ ( z, ρ θ ) in L 1 ( P 0 ,i ) and P 0 ,i -a.s. as x →∞ . Therefore, we have

<!-- formula-not-decoded -->

By (4.14) and (4.11), we have α := lim x →∞ -∑ j ∈I π θ j e θx log Φ θ ( x, j ) exists. Taking expectation in (4.13), it follows from the bounded convergence theorem and equations (4.11) (4.12) that

<!-- formula-not-decoded -->

Critical regime ρ θ ∗ = λ ′ ( θ ∗ ) = λ ( θ ∗ ) θ ∗ . let Φ θ ∗ be a travelling wave with speed ρ θ ∗ . Recall that C i ( x, ρ θ ∗ ) denotes the random collection of type i particles stopped at the barrier Γ ( x,ρ θ ∗ ) . Similarly as in the supercritical case, we have that

<!-- formula-not-decoded -->

is a P 0 ,i -martingale which converges to Φ θ ∗ ( z, i ) a.s. and in L 1 ( P 0 ,i ).

For b &gt; 0, let us also add a killing barrier at Γ ( -b,ρ θ ∗ ) for this branching MAP, which means the truncation as in (3.2). Define ˜ C i ( x, ρ θ ∗ ) to be the collection of type i particles that are stopped at the barrier Γ ( x,ρ θ ∗ ) for the truncated branching MAP and let ˜ C ( x, ρ θ ∗ ) := ⋃ i ∈I ˜ C i ( x, ρ θ ∗ ). Let γ ( -b,θ ∗ ) be the event that the branching MAP survives and remains entirely to the right of Γ ( -b,ρ θ ∗ ) , such that the truncation does not take effect on the event γ ( -b,θ ∗ ) . By (2.23) applied to θ ∗ , we know that P 0 ,i ( γ ( -b,θ ∗ ) | S ) → 1 as b → ∞ . On the event γ ( -b,θ ∗ ) , we have C i ( x, ρ θ ∗ ) = ˜ C i ( x, ρ θ ∗ ) and

<!-- formula-not-decoded -->

exists and is non-negative. Define

<!-- formula-not-decoded -->

Let ˜ F Γ ( x,ρ θ ∗ ) be the natural filtration generated by ancestral type and spatial paths receding from particles at the moment they hit Γ ( x,ρ θ ∗ ) before meeting Γ ( -b,ρ θ ∗ ) . With similar arguments as in the proof of (4.8), we deduce by the strong Markov property that, ( Z ( b ) x ( ρ θ ∗ ) , x ≥ 0) is a P 0 ,i -martingale with respect to { ˜ F Γ ( x,ρ θ ∗ ) : x ≥ 0 } and

<!-- formula-not-decoded -->

The arguments of (4.7) and (4.9) still work for θ = θ ∗ . Therefore, we have

<!-- formula-not-decoded -->

By (4.17), (4.18) and Lemma 3.1, we get that

<!-- formula-not-decoded -->

Similarly to the arguments for supercritical speed regime, we know that (# C i ( x, ρ θ ∗ ) : i ∈ I ) x ≥ 0 forms a supercritical continuous-time branching process where x plays the role of time. Again, by the Kesten-Stigum theorem ([20, Theorem 2.1]), there is a non-negative vector π θ ∗ = ( π θ ∗ i : i ∈ I ) with ⟨ π θ ∗ , 1 ⟩ = 1, such that for all i ∈ I , P 0 ,i (lim x →∞ # C j ( x, ρ θ ∗ ) / # C ( x, ρ θ ∗ ) = π θ ∗ j | S ) = 1. Therefore,

<!-- formula-not-decoded -->

Applying (4.20) to (4.19), we deduce that, for all j ∈ I ,

<!-- formula-not-decoded -->

Using (4.20) again, we have, for j ∈ I ,

<!-- formula-not-decoded -->

where ˜ π j = π θ ∗ j / ⟨ π θ ∗ , V ( θ ∗ ) ⟩ . Combining this with (4.16), we have

<!-- formula-not-decoded -->

exists and is positive. It follows that, P -a.s. on γ ( -b,ρ θ ∗ )

<!-- formula-not-decoded -->

Recalling that P 0 ,i ( γ ( -b,θ ∗ ) | S ) → 1 as b →∞ and ˜ M x ( z, ρ θ ∗ ) given by (4.15) is an L 1 -martingale, we deduce by the the bounded convergence theorem that

<!-- formula-not-decoded -->

where we used the fact that both lim x →∞ ∑ j ∈I # C j ( x, ρ θ ∗ ) log Φ θ ∗ ( z + x, j ) and Z θ ∗ ( ∞ ) are zero P 0 ,i on S c . This completes the proof.

## 5 Proof of the spine decomposition theorem

## 5.1 The spine decomposition with respect to the additive martingale

We use the same notations in Section 2.3 and give the proofs of the results in Section 2.3. First, we assume that each particle has at least one child and prove Theorems 2.7 under this assumption. Then, we will prove these results allowing the possibility of no offspring when a particle dies.

Intuitively, We can construct a probability measure P ∗ ( x,i ) on ˜ F t by

<!-- formula-not-decoded -->

where

- P x,i is the law of the Markov additive process ( X ξ ( t ) , J ξ ( t )) with MAP triplet (( ϕ i ) i ∈I , Q, G ) starting from ( x, i ), which gives the motion of the spine, and ( X ξ , J ξ ) t is short for (( X ξ ( s ) , J ξ ( s )) , 0 ≤ s ≤ t );
- Recall that n = ( n t : t ≥ 0) is the counting process of fission times along the spine, i.e. n s = | ξ s | is the generation of ξ s . We write L β ( J ξ ) for the law of a Poisson (Cox) process with rate β (Θ t )d t and n t is short

for ( n s : 0 ≤ s ≤ t ).

- µ J ξ ( d v ) ( A v ) is the probability that a particle with type J ξ ( d v ) has an offspring of size A v ;
- 1 A v represents that we choose the spine uniformly and O v is the set of v 's children except the one in the spine;
- ( τ, M ) v,j t -s stands for the marked subtree rooted at vj shifted by time d v , and the subscript t -s indicates that this time-shifted subtree evolves until time t -s .

We have defined in Lemma 2.5 that

<!-- formula-not-decoded -->

To prove that ( ζ t , t ≥ 0 , ˜ P x,i ) is a martingale, we proceeds by decomposing ζ t into the product of three parts ζ (1) t , ζ (2) t and ζ (3) t , which will be defined sequentially as the argument develops. We also need the following definition from [39].

Definition 5.1. Suppose that (Ω , H , P ) is a probability space, {H t , t ≥ 0 } is a filtration on (Ω , H ) and K is a subσ -field of H . A real-valued process { U t , t ≥ 0 } on (Ω , H , P ) is called a P ( ·|K ) -martingale with respect to {H t , t ≥ 0 } if:

- (i) It is adapted to {H t ∨ K , t ≥ 0 } ;
- (ii) For any t ≥ 0 , E | U t | &lt; ∞ ;
- (iii) For any t &gt; s ,

<!-- formula-not-decoded -->

We also say that { U t , t ≥ 0 } is a martingale with respect to {H t , t ≥ 0 } given K .

First, by [21, Theorem 5.4], we have the following lemma.

Lemma 5.2. Suppose that, given the path of the type process J ξ , n = ( n t : t ≥ 0) is a Cox process on R + with intensity β ( J ξ ( t ))d t along the path of J ξ ( t ) . Then, in the sense of Definition 5.1,

<!-- formula-not-decoded -->

is an L β ( J ξ ) -martingale with respect to the natural filtration {L t , t ≥ 0 } of n given ˜ G , where (( m -1) β )( i ) := ( m i -1) β i , and ˜ G is defined in (2.4) as the σ -field generated by the positions and types of the spine.

Define a probability measure L ( mβ )( J ξ ) by

<!-- formula-not-decoded -->

Then L ( mβ )( J ξ ) is the law of a Cox process with intensity ( mβ )( J ξ ( t ))d t .

Recall that Ξ θ ( t ) is defined by (2.8). Similarly, for any u ∈ N t , we define

<!-- formula-not-decoded -->

## Lemma 5.3. Define

Proof. Note that

Therefore,

<!-- formula-not-decoded -->

is a ˜ P x,i ( · | ̂ G ) -martingale with respect to { ˜ F t , t ≥ 0 } .

Summarizing, we check straightforwardly the identity

<!-- formula-not-decoded -->

We are now ready to prove that ( ζ t , t ≥ 0) is a martingale.

Proof of Lemma 2.5. The proof is similar to that in [48, Lemma 2.7]. ( ζ (1) t , t ≥ 0) is a ˜ P x,i ( ·| ˜ G )-martingale with respect to { ˜ F t , t ≥ 0 } , and ( ζ (3) t , t ≥ 0) is a ˜ P x,i ( ·| ̂ G )-martingale with respect to { ˜ F t , t ≥ 0 } . Note that ˜ G ⊂ ̂ G , and ζ (1) t ∈ ̂ G , ζ (3) t ∈ ˜ F t . By [39, Lemma 2.3], we have ( ζ (1) t ζ (3) t , t ≥ 0) is a ˜ P x,i ( ·| ˜ G )-martingale with respect to { ˜ F t , t ≥ 0 } . Note that ζ (2) t ∈ ˜ G , ζ (1) t ζ (3) t ∈ ˜ F t . Using [39, Lemma 2.3] again, we get that ( ζ t , t ≥ 0) is a ˜ P x,i -martingale with respect to { ˜ F t , t ≥ 0 } .

Lemma 5.5. W θ ( t ) is the projection of ζ t onto F t , that is,

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

where we used ˜ P x,i ( ✶ { ξ t = u } | F t ) = ∏ v ≺ u 1 A v . This completes the proof.

<!-- formula-not-decoded -->

Then ( ζ (2) t , t ≥ 0) is a ˜ P x,i -martingale with respect to ( ˜ G t , t ≥ 0) .

Proof. Recall that W θ ( t ) = ∑ u ∈N t e -( θX u ( t )+ λ ( θ ) t ) V J u ( t ) ( θ ). By the many-to-one formula (for example, see [23]), we have

<!-- formula-not-decoded -->

Note that E x,i [ W θ ( t )] = e -θx V i ( θ ), hence we have E x,i [Ξ θ ( t )] = Ξ θ (0). Combining this with the Markov property of a MAP, we deduce that (Ξ θ ( t ) , t ≥ 0) is a P x,i -martingale. Since we read from (5.1) that the law of ( X ξ , J ξ ) under ˜ P x,i is P x,i , the desired result follows.

The next lemma follows from [21, Theorem 5.5].

## Lemma 5.4. The process

Proof of Theorem 2.7. Recall that the probability measure ˜ P θ x,i is defined by

<!-- formula-not-decoded -->

Then by (5.1) we have

<!-- formula-not-decoded -->

Here we also use the probability measure P θ x,i given by Lemma 2.6, whose proof is postponed to Section 5.2; in particular, under P θ x,i a MAP has characteristics given by (2.9). Then we read from (5.3) the description of the particle system stated in the theorem.

Now we prove Theorem 2.7, allowing the possibility of no offspring when a particle dies. Our proof follows the construction of the spine decomposition for branching Markov processes given in [48].

We now require a slight modification to the definition of a marked tree with a distinguished spine. Let † be a fictitious node not in τ . Following the construction in [48, Page 6], a spine ξ on a marked tree ( τ, M ) is a subset of τ ∪ {†} such that

- ∅ ∈ ξ and | ξ ∩ ( N t ∪ {†} ) | = 1 for all t ≥ 0.
- If u ∈ ξ and v ≺ u , then v ∈ ξ .
- If u ∈ ξ and A u &gt; 0, then there exists a unique j = 1 , · · · , A u with uj ∈ ξ . If u ∈ ξ and A u = 0, then ξ ∩ N t is empty for all t ≥ d u . In this case, we will write u = † -1.

Then we call d †-1 the 'lifetime' of the spine. Let ξ t := u be the unique element u ∈ ξ ∩ ( N t ∪{†} ). Similar to [48, Equation (2.2)], we have

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

In this case, we also define

Define where the last equality follows from the fact that A †-1 = 0 when ξ t = † . By [48, Lemma 2.6], we know that Lemmas 5.2 and 5.4 hold in this case. By Lemma 2.6, it is easy to show that { ζ (2) t , t ≥ 0 } is a P x,i -martingale with respect to ˜ F t . Then, we have

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

and Lemma 2.5 holds. The definition of ζ t yields that ˜ P θ x,i ( ξ t ∈ N t ) = 1. Thus,

<!-- formula-not-decoded -->

Theorems 2.7 still holds.

## 5.2 Proof of Lemma 2.6

Proof of Lemma 2.6. We use the method of extended generator in [46]. Following [46] and the notations in Proposition 1.2, we first decompose χ t = χ (1) t + χ (2) t , where { χ (1) t , t ≥ 0 } and { χ (2) t , t ≥ 0 } are two independent processes,

<!-- formula-not-decoded -->

is a pure jump continuous-time Markov process, and χ (2) t behaves in law as a L´ evy process with Laplace exponent ϕ i , when Θ( t ) = i . Thus, the process ( χ (1) t , Θ( t )) has extended generator

̸

<!-- formula-not-decoded -->

̸

with domain D ( A (1) ) consisting of absolutely continuous functions for which the above integrals are finite. Notice that we have q ii = -q i = -∑ k = i q ik . For i ∈ I , the L´ evy process with Laplace exponent ϕ i has extended generator

<!-- formula-not-decoded -->

with domain C 2 ( R ) ⊂ D ( A i ).

Then the process ( χ (2) t , χ (1) t , Θ t ) has extended generator A , such that ∀ g ∈ C 2 ( R ) ⊂ D ( A i ) and ∀ f ∈ D ( A (1) ),

<!-- formula-not-decoded -->

Take ˜ g ( x ) := e -θx , ˜ f ( y, i ) := e -θy V i ( θ ) and ˜ h ( x, y, i ) := ˜ g ( x ) ˜ f ( y, i ) = e -θx e -θy V i ( θ ), we have

<!-- formula-not-decoded -->

For t ≥ 0, define

<!-- formula-not-decoded -->

By [46, Lemma 3.1], ( E ˜ h ( t ) , t ≥ 0) is a P x,i -local martingale. Since E x,i [ E ˜ h ( t )] = E x,i [ Ξ θ ( t ) Ξ θ (0) ] = 1 by (5.2), then E ˜ h is a true martingale. According to [46, Lemma 4.1][46, Theorem 4.2], define the probability change

<!-- formula-not-decoded -->

then under P θ x,i , ( χ (2) , χ (1) , Θ) has extended generator

<!-- formula-not-decoded -->

where F ∈ D ( ˜ A ) = D ( A ). Take F ( x, y, i ) = g ( x ) f ( y, i ) for any g ∈ D ( A i ) , f ∈ D ( A (1) ). Recall that ˜ h ( x, y, i ) = ˜ g ( x ) ˜ f ( y, i ), ˜ g ( x ) = e -θx and ˜ f ( y, i ) = e -θy V i ( θ ). Then

<!-- formula-not-decoded -->

where and

Moreover, with notations in (2.9), we define ˜ A i and ˜ A (1) as follows: for any g ∈ D ( ˜ A i ) = D ( A i ) and f ∈

<!-- formula-not-decoded -->

<!-- formula-not-decoded -->

D ( ˜ A (1) ) = D ( A (1) ),

<!-- formula-not-decoded -->

̸

Then by straightforward computation, we have I 1 ( y, i ) = ˜ A (1) f ( y, i ) + ( q ii -˜ q ii ) f ( y, i ), and I 2 ( x, i ) = ˜ A i g ( x ). Therefore,

<!-- formula-not-decoded -->

where the last equality is deduced from the definition of PF eigenvector ⃗ V ( θ ) of M ( θ ):

<!-- formula-not-decoded -->

This implies that, under P θ x,i , ( χ, Θ) is a MAP with the given characteristics in the lemma.

## 5.3 The spine decomposition with respect to the truncated derivative martingale

We now prove Proposition 3.3, the spine decomposition used in Section 3.2. The proof is analogous to that for the additive martingale, but with the spine's movement now governed by a MAP conditioned to stay positive (non-negative). For simplicity, we assume that each particle has at least one child; the extension to allow extinction can be treated in a similar way as what we have done in the additive martingale case. Here we fix θ = θ ∗ and let ̂ X ξ ( t ) = θ ∗ X ξ ( t ) + λ ( θ ∗ ) t , ̂ χ t = θ ∗ χ t + λ ( θ ∗ ) t .

Recall the change of measure defined in (3.3). We have already explained that the spine ( ̂ X ξ , J ξ ) has the law of a MAP conditioned to stay positive given by (3.4).

We still define ζ (1) as in Lemma 5.2 and ζ (3) as in Lemma 5.4. Analogously to ζ (2) in Lemma 5.3, we define

<!-- formula-not-decoded -->

where ( R j ( x ) , j ∈ I , x ∈ R + ) is defined in (3.1), as the renewal function of ( ̂ X ξ , J ξ ) under ˜ P θ ∗ x,i . By Lemma 5.3 and the definition of P ↑ x,i in (3.4), the process ( ̂ X ξ , J ξ ) under ˜ P ↑ x,i has the same law as ( χ, Θ) under P ↑ x,i , i.e. it is a MAP conditioned to stay above -b . By Lemma 5.3 again, ( ζ (2) t , t ≥ 0) is a ˜ P x,i -martingale with respect to ( ˜ G t , t ≥ 0), therefore ( ζ (2) ↑ t , t ≥ 0) is a ˜ P ↑ x,i -martingale with respect to ( ˜ G t , t ≥ 0).

Then we set

<!-- formula-not-decoded -->

Then ( ζ ↑ t , t ≥ 0 , ˜ P x,i ) is a martingale with respect to { ˜ F t , t ≥ 0 } . So we can define

<!-- formula-not-decoded -->

Similarly as (5.3), we can decompose

<!-- formula-not-decoded -->

This matches the description the branching MAP under ˜ P ↑ x,i in Proposition 3.3.

## Acknowledgement

This work is partially supported by the National Key R&amp;D Program of China (grant 2022YFA1006500) and National Natural Science Foundation of China (Grant Nos. 12288201 and 12301169).

## References

- [1] E. A¨ ıd´ ekon. Convergence in law of the minimum of a branching random walk. Ann. Probab. , 41(3A):13621426, 2013.
- [2] G. Alsmeyer and B. Mallein. A simple method to find all solutions to the functional equation of the smoothing transform. J. Theoret. Probab. , 35(4):2569-2599, 2022.
- [3] M. Andr´ e and J.-J. Duchamps. Sharp L log L condition for supercritical Galton-Watson processes with countable types. arXiv:2503.05575 [math.PR], 2025.
- [4] S. Asmussen. Applied probability and queues , volume 51 of Applications of Mathematics (New York) . Springer-Verlag, New York, second edition, 2003. Stochastic Modelling and Applied Probability.
- [5] K. B. Athreya. Some results on multitype continuous time Markov branching processes. Ann. Math. Statist. , 39:347-357, 1968.
- [6] S. Baguley, L. D¨ oring, and A. Kyprianou. General path integrals and stable SDEs. Journal of the European Mathematical Society , 26(9):3243-3286, 2024.
- [7] M. A. Belloum and B. Mallein. Anomalous spreading in reducible multitype branching Brownian motion. Electron. J. Probab. , 26:Paper No. 61, 39, 2021.
- [8] J. Bertoin and B. Mallein. Biggins' martingale convergence for branching L´ evy processes. Electron. Commun. Probab. , 23:Paper No. 83, 12, 2018.
- [9] J. Bertoin and B. Mallein. Infinitely ramified point measures and branching L´ evy processes. Ann. Probab. , 47(3):1619-1652, 2019.
- [10] J. Blath, M. Hammer, D. Jacobi, and F. Nie. How the interplay of dormancy and selection affects the wave of advance of an advantageous gene. Stochastic Process. Appl. , 181:Paper No. 104537, 25, 2025.
- [11] A. Bovier. Gaussian processes on trees , volume 163 of Cambridge Studies in Advanced Mathematics . Cambridge University Press, Cambridge, 2017. From spin glasses to branching Brownian motion.

- [12] A. Champneys, S. Harris, J. Toland, J. Warren, and D. Williams. Algebra, analysis and probability for a coupled system of reaction-diffusion equations. Philos. Trans. Roy. Soc. London Ser. A , 350(1692):69-112, 1995.
- [13] L. Chaumont and R. A. Doney. On L´ evy processes conditioned to stay positive. Electron. J. Probab. , 10:no. 28, 948-961, 2005.
- [14] B. Chauvin. Product martingales and stopping lines for branching Brownian motion. Ann. Probab. , 19(3):1195-1205, 1991.
- [15] X. Chen. A necessary and sufficient condition for the nontrivial limit of the derivative martingale in a branching random walk. Adv. in Appl. Probab. , 47(3):741-760, 2015.
- [16] W. Da Silva. Self-similar signed growth-fragmentations. Electron. J. Probab. , 28:Paper No. 49, 45, 2023.
- [17] W. Da Silva and J. C. Pardo. Multitype self-similar growth-fragmentation processes. ALEA Lat. Am. J. Probab. Math. Stat. , 21(2):985-1040, 2024.
- [18] S. Dereich, L. D¨ oring, and A. E. Kyprianou. Real self-similar processes started from the origin. Ann. Probab. , 45(3):1952-2003, 2017.
- [19] R. Durrett. Probability-theory and examples , volume 49 of Cambridge Series in Statistical and Probabilistic Mathematics . Cambridge University Press, Cambridge, fifth edition, 2019.
- [20] H.-O. Georgii and E. Baake. Supercritical multitype branching processes: the ancestral types of typical individuals. Adv. in Appl. Probab. , 35(4):1090-1110, 2003.
- [21] R. Hardy and S. C. Harris. A spine approach to branching diffusions with applications to L p -convergence of martingales. In S´ eminaire de Probabilit´ es XLII , volume 1979 of Lecture Notes in Math. , pages 281-330. Springer, Berlin, 2009.
- [22] S. C. Harris. Travelling-waves for the FKPP equation via probabilistic arguments. Proc. Roy. Soc. Edinburgh Sect. A , 129(3):503-517, 1999.
- [23] S. C. Harris and M. I. Roberts. The many-to-few lemma and multiple spines. Ann. Inst. Henri Poincar´ e Probab. Stat. , 53(1):226-242, 2017.
- [24] T. E. Harris. The theory of branching processes , volume Band 119 of Die Grundlehren der mathematischen Wissenschaften . Springer-Verlag, Berlin; Prentice Hall, Inc., Englewood Cliffs, NJ, 1963.
- [25] R. A. Horn and C. R. Johnson. Matrix Analysis . Cambridge University Press, 2 edition, 2012.
- [26] H. Hou, Y. Jiang, Y.-X. Ren, and R. Song. Tail probability of maximal displacement in critical branching L´ evy process with stable branching. Bernoulli , 31(1):630-648, 2025.
- [27] H. Hou, Y.-X. Ren, and R. Song. Extremal process for irreducible multi-type branching Brownian motion. ALEA Lat. Am. J. Probab. Math. Stat. , 21(2):1417-1473, 2024.
- [28] H. Hou, Y.-X. Ren, and R. Song. Tails of Extinction Time and Maximal Displacement for Critical Branching Killed L´ evy Process. Potential Anal. , 63(4):1811-1867, 2025.
- [29] J. Ivanovs. One-sided Markov additive processes and related exit problems . Phd thesis, University of Amsterdam, Amsterdam, September 2011. Available at https://pure.uva.nl/ws/files/1408093/94456\_ 0\_Thesis.pdf .

- [30] P. Jagers. General branching processes as Markov fields. Stochastic Process. Appl. , 32(2):183-212, 1989.
- [31] H. Kesten and B. P. Stigum. A limit theorem for multidimensional Galton-Watson processes. Ann. Math. Statist. , 37:1211-1223, 1966.
- [32] J. F. C. Kingman. A convexity property of positive matrices. The Quarterly Journal of Mathematics , 12(1):283-284, 01 1961.
- [33] M. Kolb and M. Savov. A characterization of the finiteness of perpetual integrals of L´ evy processes. Bernoulli , 26(2):1453-1472, 2020.
- [34] A. Kyprianou. Travelling wave solutions to the K-P-P equation: alternatives to Simon Harris' probabilistic analysis. Annales de l'Institut Henri Poincare (B) Probability and Statistics , 40(1):53-72, 2004.
- [35] A. E. Kyprianou. A note on branching L´ evy processes. Stochastic Process. Appl. , 82(1):1-14, 1999.
- [36] A. E. Kyprianou, R.-L. Liu, A. Murillo-Salas, and Y.-X. Ren. Supercritical super-Brownian motion with a general branching mechanism and travelling waves. Ann. Inst. Henri Poincar´ e Probab. Stat. , 48(3):661687, 2012.
- [37] S. P. Lalley. Conditional Markov renewal theory. I. Finite and denumerable state space. Ann. Probab. , 12(4):1113-1148, 1984.
- [38] S. P. Lalley and T. Sellke. A conditional limit theorem for the frontier of a branching Brownian motion. Ann. Probab. , 15(3):1052-1061, 1987.
- [39] R.-L. Liu, Y.-X. Ren, and R. Song. L log L condition for supercritical branching Hunt processes. J. Theoret. Probab. , 24(1):170-193, 2011.
- [40] R. Lyons. A simple path to Biggins' martingale convergence for branching random walk. In Classical and modern branching processes (Minneapolis, MN, 1994) , volume 84 of IMA Vol. Math. Appl. , pages 217-221. Springer, New York, 1997.
- [41] H. Ma and Y.-X. Ren. Double jump in the maximum of two-type reducible branching Brownian motion. arXiv:2305.09988v3 [math.PR], 2023.
- [42] P. Maillard and O. Tough. Generalised principal eigenvalues and global survival of branching Markov processes. arXiv:2505.12127 [math.PR], 2025.
- [43] B. Mallein and Q. Shi. A necessary and sufficient condition for the convergence of the derivative martingale in a branching L´ evy process. Bernoulli , 29(1):597-624, 2023.
- [44] H. P. McKean. Application of Brownian motion to the equation of Kolmogorov-Petrovskii-Piskunov. Comm. Pure Appl. Math. , 28(3):323-331, 1975.
- [45] J. Neveu. Multiplicative martingales for spatial branching processes. In Seminar on Stochastic Processes, 1987 (Princeton, NJ, 1987) , volume 15 of Progr. Probab. Statist. , pages 223-242. Birkh¨ auser Boston, Boston, MA, 1988.
- [46] Z. Palmowski and T. Rolski. A technique for exponential change of measure for Markov processes. Bernoulli , 8(6):767-785, 2002.
- [47] C. Profeta. Maximal displacement of spectrally negative branching L´ evy processes. Bernoulli , 30(2):961982, 2024.

- [48] Y.-X. Ren and R. Song. Spine decomposition for branching Markov processes and its applications. Sci. Sin. Math. , 51:1819-1844, 2021. (In Chinese). (For English version, see arXiv:2007.12495).
- [49] Y.-X. Ren, R. Song, and R. Zhang. Moments of additive martingales of branching L´ evy processes and applications, 2025. arXiv:2509.09188 [math.PR].
- [50] Y.-X. Ren and T. Yang. Multitype branching Brownian motion and traveling waves. Adv. in Appl. Probab. , 46(1):217-240, 2014.
- [51] K.-i. Sato. L´ evy processes and infinitely divisible distributions , volume 68 of Cambridge Studies in Advanced Mathematics . Cambridge University Press, Cambridge, 1999. Translated from the 1990 Japanese original, Revised by the author.
- [52] E. Seneta. Nonnegative matrices and Markov chains . Springer Series in Statistics. Springer-Verlag, New York, second edition, 1981.
- [53] Z. Shi. Branching random walks , volume 2151 of Lecture Notes in Mathematics . Springer, Cham, 2015. Lecture notes from the 42nd Probability Summer School held in Saint Flour, 2012, ´ Ecole d' ´ Et´ e de Probabilit´ es de Saint-Flour. [Saint-Flour Probability Summer School].
- [54] F. Spitzer. Principles of random walk , volume Vol. 34 of Graduate Texts in Mathematics . Springer-Verlag, New York-Heidelberg, second edition, 1976.
- [55] T. Yang and Y.-X. Ren. Limit theorem for derivative martingale at criticality w.r.t. branching Brownian motion. Statist. Probab. Lett. , 81(2):195-200, 2011.